use std::collections::HashMap;
use std::sync::{Mutex, RwLock};

use iter_extended::vecmap;
use noirc_frontend::monomorphization::ast::{self, LocalId, Parameters};
use noirc_frontend::monomorphization::ast::{FuncId, Program};
use noirc_frontend::Signedness;

use crate::ssa_refactor::ir::function::Function;
use crate::ssa_refactor::ir::function::FunctionId as IrFunctionId;
use crate::ssa_refactor::ir::instruction::BinaryOp;
use crate::ssa_refactor::ir::map::AtomicCounter;
use crate::ssa_refactor::ir::types::Type;
use crate::ssa_refactor::ir::value::ValueId;
use crate::ssa_refactor::ssa_builder::FunctionBuilder;

use super::value::{Tree, Value, Values};

/// The FunctionContext is the main context object for translating a
/// function into SSA form during the SSA-gen pass.
///
/// This context can be used to build any amount of functions,
/// so long as it is cleared out in between each function via
/// calling self.new_function().
///
/// If compiling many functions across multiple threads, there should
/// be a separate FunctionContext for each thread. Each FunctionContext
/// can communicate via the SharedContext field which as its name suggests
/// is the only part of the context that needs to be shared between threads.
pub(super) struct FunctionContext<'a> {
    definitions: HashMap<LocalId, Values>,

    pub(super) builder: FunctionBuilder,
    shared_context: &'a SharedContext,
}

/// Shared context for all functions during ssa codegen. This is the only
/// object that is shared across all threads when generating ssa in multiple threads.
///
/// The main job of the SharedContext is to remember which functions are already
/// compiled, what their IDs are, and keep a queue of which functions still need to
/// be compiled.
///
/// SSA can be generated by continuously popping from this function_queue and using
/// FunctionContext to generate from the popped function id. Once the queue is empty,
/// no other functions are reachable and the SSA generation is finished.
pub(super) struct SharedContext {
    /// All currently known functions which have already been assigned function ids.
    /// These functions are all either currently having their SSA generated or are
    /// already finished.
    functions: RwLock<HashMap<FuncId, IrFunctionId>>,

    /// Queue of which functions still need to be compiled.
    ///
    /// The queue is currently Last-in First-out (LIFO) but this is an
    /// implementation detail that can be trivially changed and should
    /// not impact the resulting SSA besides changing which IDs are assigned
    /// to which functions.
    function_queue: Mutex<FunctionQueue>,

    /// Shared counter used to assign the ID of the next function
    function_counter: AtomicCounter<Function>,

    /// The entire monomorphized source program
    pub(super) program: Program,
}

/// The queue of functions remaining to compile
type FunctionQueue = Vec<(ast::FuncId, IrFunctionId)>;

impl<'a> FunctionContext<'a> {
    /// Create a new FunctionContext to compile the first function in the shared_context's
    /// function queue.
    ///
    /// This will pop from the function queue, so it is expected the shared_context's function
    /// queue is non-empty at the time of calling this function. This can be ensured by calling
    /// `shared_context.get_or_queue_function(function_to_queue)` before calling this constructor.
    ///
    /// `function_name` and `parameters` are expected to be the name and parameters of the function
    /// this constructor will pop from the function queue.
    pub(super) fn new(
        function_name: String,
        parameters: &Parameters,
        shared_context: &'a SharedContext,
    ) -> Self {
        let function_id = shared_context
            .pop_next_function_in_queue()
            .expect("No function in queue for the FunctionContext to compile")
            .1;

        let builder = FunctionBuilder::new(function_name, function_id);
        let mut this = Self { definitions: HashMap::new(), builder, shared_context };
        this.add_parameters_to_scope(parameters);
        this
    }

    /// Finish building the current function and switch to building a new function with the
    /// given name, id, and parameters.
    ///
    /// Note that the previous function cannot be resumed after calling this. Developers should
    /// avoid calling new_function until the previous function is completely finished with ssa-gen.
    pub(super) fn new_function(&mut self, id: IrFunctionId, name: String, parameters: &Parameters) {
        self.definitions.clear();
        self.builder.new_function(name, id);
        self.add_parameters_to_scope(parameters);
    }

    /// Add each parameter to the current scope, and return the list of parameter types.
    ///
    /// The returned parameter type list will be flattened, so any struct parameters will
    /// be returned as one entry for each field (recursively).
    fn add_parameters_to_scope(&mut self, parameters: &Parameters) {
        for (id, mutable, _, typ) in parameters {
            self.add_parameter_to_scope(*id, typ, *mutable);
        }
    }

    /// Adds a "single" parameter to scope.
    ///
    /// Single is in quotes here because in the case of tuple parameters, the tuple is flattened
    /// into a new parameter for each field recursively.
    fn add_parameter_to_scope(
        &mut self,
        parameter_id: LocalId,
        parameter_type: &ast::Type,
        mutable: bool,
    ) {
        // Add a separate parameter for each field type in 'parameter_type'
        let parameter_value = Self::map_type(parameter_type, |typ| {
            let value = self.builder.add_parameter(typ);
            if mutable {
                self.new_mutable_variable(value)
            } else {
                value.into()
            }
        });

        self.definitions.insert(parameter_id, parameter_value);
    }

    /// Allocate a single slot of memory and store into it the given initial value of the variable.
    /// Always returns a Value::Mutable wrapping the allocate instruction.
    pub(super) fn new_mutable_variable(&mut self, value_to_store: ValueId) -> Value {
        let alloc = self.builder.insert_allocate(1);
        self.builder.insert_store(alloc, value_to_store);
        let typ = self.builder.type_of_value(value_to_store);
        Value::Mutable(alloc, typ)
    }

    /// Maps the given type to a Tree of the result type.
    ///
    /// This can be used to (for example) flatten a tuple type, creating
    /// and returning a new parameter for each field type.
    pub(super) fn map_type<T>(typ: &ast::Type, mut f: impl FnMut(Type) -> T) -> Tree<T> {
        Self::map_type_helper(typ, &mut f)
    }

    // This helper is needed because we need to take f by mutable reference,
    // otherwise we cannot move it multiple times each loop of vecmap.
    fn map_type_helper<T>(typ: &ast::Type, f: &mut impl FnMut(Type) -> T) -> Tree<T> {
        match typ {
            ast::Type::Tuple(fields) => {
                Tree::Branch(vecmap(fields, |field| Self::map_type_helper(field, f)))
            }
            other => Tree::Leaf(f(Self::convert_non_tuple_type(other))),
        }
    }

    /// Convert a monomorphized type to an SSA type, preserving the structure
    /// of any tuples within.
    pub(super) fn convert_type(typ: &ast::Type) -> Tree<Type> {
        // Do nothing in the closure here - map_type_helper already calls
        // convert_non_tuple_type internally.
        Self::map_type_helper(typ, &mut |x| x)
    }

    /// Converts a non-tuple type into an SSA type. Panics if a tuple type is passed.
    ///
    /// This function is needed since this SSA IR has no concept of tuples and thus no type for
    /// them. Use `convert_type` if tuple types need to be handled correctly.
    pub(super) fn convert_non_tuple_type(typ: &ast::Type) -> Type {
        match typ {
            ast::Type::Field => Type::field(),
            ast::Type::Array(_, _) => Type::Reference,
            ast::Type::Integer(Signedness::Signed, bits) => Type::signed(*bits),
            ast::Type::Integer(Signedness::Unsigned, bits) => Type::unsigned(*bits),
            ast::Type::Bool => Type::unsigned(1),
            ast::Type::String(_) => Type::Reference,
            ast::Type::Unit => Type::Unit,
            ast::Type::Tuple(_) => panic!("convert_non_tuple_type called on a tuple: {typ}"),
            ast::Type::Function(_, _) => Type::Function,

            // How should we represent Vecs?
            // Are they a struct of array + length + capacity?
            // Or are they just references?
            ast::Type::Vec(_) => Type::Reference,
        }
    }

    /// Insert a unit constant into the current function if not already
    /// present, and return its value
    pub(super) fn unit_value(&mut self) -> Values {
        self.builder.numeric_constant(0u128, Type::Unit).into()
    }

    /// Insert a binary instruction at the end of the current block.
    /// Converts the form of the binary instruction as necessary
    /// (e.g. swapping arguments, inserting a not) to represent it in the IR.
    /// For example, (a <= b) is represented as !(b < a)
    pub(super) fn insert_binary(
        &mut self,
        mut lhs: ValueId,
        operator: noirc_frontend::BinaryOpKind,
        mut rhs: ValueId,
    ) -> Values {
        let op = convert_operator(operator);

        if operator_requires_swapped_operands(operator) {
            std::mem::swap(&mut lhs, &mut rhs);
        }

        let mut result = self.builder.insert_binary(lhs, op, rhs);

        if operator_requires_not(operator) {
            result = self.builder.insert_not(result);
        }
        result.into()
    }

    /// Inserts a call instruction at the end of the current block and returns the results
    /// of the call.
    ///
    /// Compared to self.builder.insert_call, this version will reshape the returned Vec<ValueId>
    /// back into a Values tree of the proper shape.
    pub(super) fn insert_call(
        &mut self,
        function: ValueId,
        arguments: Vec<ValueId>,
        result_type: &ast::Type,
    ) -> Values {
        let result_types = Self::convert_type(result_type).flatten();
        let results = self.builder.insert_call(function, arguments, result_types);

        let mut i = 0;
        let reshaped_return_values = Self::map_type(result_type, |_| {
            let result = results[i].into();
            i += 1;
            result
        });
        assert_eq!(i, results.len());
        reshaped_return_values
    }

    /// Create a const offset of an address for an array load or store
    pub(super) fn make_offset(&mut self, mut address: ValueId, offset: u128) -> ValueId {
        if offset != 0 {
            let offset = self.builder.field_constant(offset);
            address = self.builder.insert_binary(address, BinaryOp::Add, offset);
        }
        address
    }

    /// Define a local variable to be some Values that can later be retrieved
    /// by calling self.lookup(id)
    pub(super) fn define(&mut self, id: LocalId, value: Values) {
        let existing = self.definitions.insert(id, value);
        assert!(existing.is_none(), "Variable {id:?} was defined twice in ssa-gen pass");
    }

    /// Looks up the value of a given local variable. Expects the variable to have
    /// been previously defined or panics otherwise.
    pub(super) fn lookup(&self, id: LocalId) -> Values {
        self.definitions.get(&id).expect("lookup: variable not defined").clone()
    }

    /// Extract the given field of the tuple. Panics if the given Values is not
    /// a Tree::Branch or does not have enough fields.
    pub(super) fn get_field(tuple: Values, field_index: usize) -> Values {
        match tuple {
            Tree::Branch(mut trees) => trees.remove(field_index),
            Tree::Leaf(value) => {
                unreachable!("Tried to extract tuple index {field_index} from non-tuple {value:?}")
            }
        }
    }

    /// Mutate lhs to equal rhs
    pub(crate) fn assign(&mut self, lhs: Values, rhs: Values) {
        match (lhs, rhs) {
            (Tree::Branch(lhs_branches), Tree::Branch(rhs_branches)) => {
                assert_eq!(lhs_branches.len(), rhs_branches.len());

                for (lhs, rhs) in lhs_branches.into_iter().zip(rhs_branches) {
                    self.assign(lhs, rhs);
                }
            }
            (Tree::Leaf(lhs), Tree::Leaf(rhs)) => {
                let (lhs, rhs) = (lhs.eval_reference(), rhs.eval(self));
                self.builder.insert_store(lhs, rhs);
            }
            (lhs, rhs) => {
                unreachable!(
                    "assign: Expected lhs and rhs values to match but found {lhs:?} and {rhs:?}"
                )
            }
        }
    }

    /// Retrieves the given function, adding it to the function queue
    /// if it is not yet compiled.
    pub(super) fn get_or_queue_function(&mut self, id: FuncId) -> Values {
        let function = self.shared_context.get_or_queue_function(id);
        self.builder.import_function(function).into()
    }
}

/// True if the given operator cannot be encoded directly and needs
/// to be represented as !(some other operator)
fn operator_requires_not(op: noirc_frontend::BinaryOpKind) -> bool {
    use noirc_frontend::BinaryOpKind::*;
    matches!(op, NotEqual | LessEqual | GreaterEqual)
}

/// True if the given operator cannot be encoded directly and needs
/// to have its lhs and rhs swapped to be represented with another operator.
/// Example: (a > b) needs to be represented as (b < a)
fn operator_requires_swapped_operands(op: noirc_frontend::BinaryOpKind) -> bool {
    use noirc_frontend::BinaryOpKind::*;
    matches!(op, Greater | LessEqual)
}

/// Converts the given operator to the appropriate BinaryOp.
/// Take care when using this to insert a binary instruction: this requires
/// checking operator_requires_not and operator_requires_swapped_operands
/// to represent the full operation correctly.
fn convert_operator(op: noirc_frontend::BinaryOpKind) -> BinaryOp {
    use noirc_frontend::BinaryOpKind;
    match op {
        BinaryOpKind::Add => BinaryOp::Add,
        BinaryOpKind::Subtract => BinaryOp::Sub,
        BinaryOpKind::Multiply => BinaryOp::Mul,
        BinaryOpKind::Divide => BinaryOp::Div,
        BinaryOpKind::Modulo => BinaryOp::Mod,
        BinaryOpKind::Equal => BinaryOp::Eq,
        BinaryOpKind::NotEqual => BinaryOp::Eq, // Requires not
        BinaryOpKind::Less => BinaryOp::Lt,
        BinaryOpKind::Greater => BinaryOp::Lt, // Requires operand swap
        BinaryOpKind::LessEqual => BinaryOp::Lt, // Requires operand swap and not
        BinaryOpKind::GreaterEqual => BinaryOp::Lt, // Requires not
        BinaryOpKind::And => BinaryOp::And,
        BinaryOpKind::Or => BinaryOp::Or,
        BinaryOpKind::Xor => BinaryOp::Xor,
        BinaryOpKind::ShiftRight => BinaryOp::Shr,
        BinaryOpKind::ShiftLeft => BinaryOp::Shl,
    }
}

impl SharedContext {
    /// Create a new SharedContext for the given monomorphized program.
    pub(super) fn new(program: Program) -> Self {
        Self {
            functions: Default::default(),
            function_queue: Default::default(),
            function_counter: Default::default(),
            program,
        }
    }

    /// Pops the next function from the shared function queue, returning None if the queue is empty.
    pub(super) fn pop_next_function_in_queue(&self) -> Option<(ast::FuncId, IrFunctionId)> {
        self.function_queue.lock().expect("Failed to lock function_queue").pop()
    }

    /// Return the matching id for the given function if known. If it is not known this
    /// will add the function to the queue of functions to compile, assign it a new id,
    /// and return this new id.
    pub(super) fn get_or_queue_function(&self, id: ast::FuncId) -> IrFunctionId {
        // Start a new block to guarantee the destructor for the map lock is released
        // before map needs to be aquired again in self.functions.write() below
        {
            let map = self.functions.read().expect("Failed to read self.functions");
            if let Some(existing_id) = map.get(&id) {
                return *existing_id;
            }
        }

        let next_id = self.function_counter.next();

        let mut queue = self.function_queue.lock().expect("Failed to lock function queue");
        queue.push((id, next_id));

        self.functions.write().expect("Failed to write to self.functions").insert(id, next_id);

        next_id
    }
}
