---
source: tooling/nargo_cli/tests/execute.rs
expression: artifact
---
{
  "noir_version": "[noir_version]",
  "hash": "[hash]",
  "abi": {
    "parameters": [
      {
        "name": "x",
        "type": {
          "kind": "field"
        },
        "visibility": "private"
      },
      {
        "name": "y",
        "type": {
          "kind": "field"
        },
        "visibility": "private"
      },
      {
        "name": "salt",
        "type": {
          "kind": "field"
        },
        "visibility": "private"
      },
      {
        "name": "out_x",
        "type": {
          "kind": "field"
        },
        "visibility": "private"
      },
      {
        "name": "out_y",
        "type": {
          "kind": "field"
        },
        "visibility": "private"
      },
      {
        "name": "out_hash",
        "type": {
          "kind": "field"
        },
        "visibility": "private"
      }
    ],
    "return_type": null,
    "error_types": {
      "12049594436772143978": {
        "error_kind": "string",
        "string": "array ref-count underflow detected"
      },
      "17843811134343075018": {
        "error_kind": "string",
        "string": "Stack too deep"
      }
    }
  },
  "bytecode": "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",
  "debug_symbols": "1Z3Rbts4EEX/xc95IIcznGF/pVgESZoWBoykSNIFFkH/fWUn0jqRKq+oXGf4EsSN7vGp7UvKNk0/b77dXv/6cbm9+37/uPny9Xmzu7+5etre33WXnn9fbK4ftrvd9sfl8T9vwv5HosPxjz+v7vYXH5+uHp42X2Kgi83t3bfuNw5d/vt2d7v5It2v40Mjp/7YaDocHMvUwZJCf7DIm4P/utik5MiFHbmII5fsyEUduZgjl+LHhYMjl+jIxdG4y47GXXY07rKjcZcdjbvsaNzlM4+70QYXGrkUPy4SHLlERy7kyCU5cmFHLuLIJTtyUUcujsZdcTTuZkfjbj7zuGu5PzhLmj84hayvB6dI+b04tSqeWhXnVsWlVfHcqri2Km6tipdGxTW0Kt7qzKmtzpza6syprc6c2urMqa3OnNrqzKmtzpza6sxprc6c1urMaa3OnOZl5ty7eJkM9y5e5re9i5cpa+/iZRbau3iZWPYuXuaKzqV4Gf73Lucd0bOUwaXIexdy5JIcubAjF3Hkkh25qCMXc+RS/LjEEDzJTI+8MlxB1mOZQ4SWR9LyCC+PTI8KFvvI0X+/j+TlEV0eseWRyUcsDW/FUbb5BwmF4X6nkMP7+z0GMD+C+QTmJzCfwXwB8zOYr2C+gfng/hK4vwTuL4H7S+D+Eri/BO4vgftL4P4SuL8E7m9a3d+YpD82Ko/4EcwnMD+B+QzmC5ifwXwF8w3ML1g+g/vL4P4yuL8M7i+D+8vg/jK4vwzuL4P7y+D+Cri/Au6vgPsr4P4KuL8C7q+A+yur+0s88Lt3dEd8A/MLlp8DmB/BfALzE5jPYP7qx2dKceCnEV9X37+p9C9FE4c84q++f5kHf5Y44icwn8F8AfMzmK9gvoH5Bcu3AOZHMB/cXwP318D9NXB/DdxfA/fXwP01cH/L6v6KDvw8WlAYy+r+5kTDsTx6X7sQmJ/AfAbzBczPYL6C+QbmFyifQgDzI5hPYH4C8xnMFzA/g/kK5huYD+5vBPc3gvsbwf2N4P5GcH8juL8R3N8I7u/69TlZh9dnlNKIX7D89etzTvAjmE9gfgLzGcwXMD+D+Qrmf2x/84hfsPw/rM8xfs2kQMf8QyQuj9DySFoemexCisMH/hKPIrI8kpdHdHnElkcmHypM/S3GKb2PTK/umI/EExHWUWTy3udh3Rjr6K6cXlbB1keETjzsP3BbRJpeg/FZMuJJJnuSUU8y5kmmOJKZXpHyWTLxvDJzW8zR9FqXz5JJnmTYk4x4ksmeZNSTjHmSKY5k8plH4A/bnoNybNacmjVPzZpzs+bSrHlu1lybNbdmzUur5trsHKpe5tCDjJdp8SDjZaY7yHiZvA4yXuajg4yXKeYg42XWOMh4mQgOMucd22e3fyELnmSiJxnyJJM8ybAnGfEkkz3JqCcZ8yQzOQLLsB5aVD90Oph9pX16ofVnyURPMuRJJnmSYU8y4kkme5JRTzJ2XpnZV9pL8SOTQvAkEz3JkCeZ5EmGPcmIJ5nsSebMI/DcE/8UzJNMcSQTgyeZ6EmGPMkkTzLsSea8I/Ds09sUsycZ9SRjnmSKIxkKnmSiJxnyJJM8ybAnmVMjsJVjmUMkL4/o8ogtjqzfG3Z276O0fm/YpDzwbcwnMD+B+byaL/k//uhsYf3esCf4GcxXMN/A/ILlr98b9gQ/gvnr+zsM7N1VjfkJzGcwX8D8DOYrmG9gfsHy1+8Ne4IfwXxwfwXcXwH3V8D9FXB/BdxfAfdXwP1dvzcsh+G7G5jKiB/BfALzE5jPYL6A+RnMVzDfwPyC5Su4vwru7/q9f2f3Fk7r9/49wWcwX8D8DOYrmG9gfsHy1+/9e4IfwXxwfw3cXwP318D9NXB/DdxfA/fXwP0t4P4WcH8LuL8F3N8C7m/B9pen1yN1Twv6NyW6M9Q3X3gyvgYbvg3Zjj+ppy/8DOYrmG9gfsHyp5frfCA/gvkE5k+OD91paV+a7gzp/YbrPL2epTtX1rnQdNOUy1wo14S0JmQVoem3ZVnKsJNaPvqC9JhfQloTsppQqQhNv6N7KhRrQlQTSjUhrglJTeh/PCLSKKQ1IasJlYoQh5pQrAjlmmrkmmrkmmpoTTW0phpaUw2tqYbWVENrqqE1g6XWVENrqqE11bCaalhNNYxqQpM3eeY+82Z56MsJwfQTzvnI5M2drT9FyWajSJmO9J8K0jC6lulnen+O/O4u/X31sL263t0+don9H3/d3Txt7+9eLz7987P/y/XDdrfb/rj8+XB/c/vt18Pt5e7+Zv+3TXj98ZW7m4CzdCqHc8pU7IJD2l/c351MdMHE3bV21/wv",
  "file_map": {
    "16": {
      "source": "use crate::cmp::Eq;\nuse crate::hash::Hash;\nuse crate::ops::arith::{Add, Neg, Sub};\n\n/// A point on the embedded elliptic curve\n/// By definition, the base field of the embedded curve is the scalar field of the proof system curve, i.e the Noir Field.\n/// x and y denotes the Weierstrass coordinates of the point, if is_infinite is false.\npub struct EmbeddedCurvePoint {\n    pub x: Field,\n    pub y: Field,\n    pub is_infinite: bool,\n}\n\nimpl EmbeddedCurvePoint {\n    /// Elliptic curve point doubling operation\n    /// returns the doubled point of a point P, i.e P+P\n    pub fn double(self) -> EmbeddedCurvePoint {\n        embedded_curve_add(self, self)\n    }\n\n    /// Returns the null element of the curve; 'the point at infinity'\n    pub fn point_at_infinity() -> EmbeddedCurvePoint {\n        EmbeddedCurvePoint { x: 0, y: 0, is_infinite: true }\n    }\n\n    /// Returns the curve's generator point.\n    pub fn generator() -> EmbeddedCurvePoint {\n        // Generator point for the grumpkin curve (y^2 = x^3 - 17)\n        EmbeddedCurvePoint {\n            x: 1,\n            y: 17631683881184975370165255887551781615748388533673675138860, // sqrt(-16)\n            is_infinite: false,\n        }\n    }\n}\n\nimpl Add for EmbeddedCurvePoint {\n    /// Adds two points P+Q, using the curve addition formula, and also handles point at infinity\n    fn add(self, other: EmbeddedCurvePoint) -> EmbeddedCurvePoint {\n        embedded_curve_add(self, other)\n    }\n}\n\nimpl Sub for EmbeddedCurvePoint {\n    /// Points subtraction operation, using addition and negation\n    fn sub(self, other: EmbeddedCurvePoint) -> EmbeddedCurvePoint {\n        self + other.neg()\n    }\n}\n\nimpl Neg for EmbeddedCurvePoint {\n    /// Negates a point P, i.e returns -P, by negating the y coordinate.\n    /// If the point is at infinity, then the result is also at infinity.\n    fn neg(self) -> EmbeddedCurvePoint {\n        EmbeddedCurvePoint { x: self.x, y: -self.y, is_infinite: self.is_infinite }\n    }\n}\n\nimpl Eq for EmbeddedCurvePoint {\n    /// Checks whether two points are equal\n    fn eq(self: Self, b: EmbeddedCurvePoint) -> bool {\n        (self.is_infinite & b.is_infinite)\n            | ((self.is_infinite == b.is_infinite) & (self.x == b.x) & (self.y == b.y))\n    }\n}\n\nimpl Hash for EmbeddedCurvePoint {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: crate::hash::Hasher,\n    {\n        if self.is_infinite {\n            self.is_infinite.hash(state);\n        } else {\n            self.x.hash(state);\n            self.y.hash(state);\n        }\n    }\n}\n\n/// Scalar for the embedded curve represented as low and high limbs\n/// By definition, the scalar field of the embedded curve is base field of the proving system curve.\n/// It may not fit into a Field element, so it is represented with two Field elements; its low and high limbs.\npub struct EmbeddedCurveScalar {\n    pub lo: Field,\n    pub hi: Field,\n}\n\nimpl EmbeddedCurveScalar {\n    pub fn new(lo: Field, hi: Field) -> Self {\n        EmbeddedCurveScalar { lo, hi }\n    }\n\n    #[field(bn254)]\n    pub fn from_field(scalar: Field) -> EmbeddedCurveScalar {\n        let (a, b) = crate::field::bn254::decompose(scalar);\n        EmbeddedCurveScalar { lo: a, hi: b }\n    }\n\n    //Bytes to scalar: take the first (after the specified offset) 16 bytes of the input as the lo value, and the next 16 bytes as the hi value\n    #[field(bn254)]\n    pub(crate) fn from_bytes(bytes: [u8; 64], offset: u32) -> EmbeddedCurveScalar {\n        let mut v = 1;\n        let mut lo = 0 as Field;\n        let mut hi = 0 as Field;\n        for i in 0..16 {\n            lo = lo + (bytes[offset + 31 - i] as Field) * v;\n            hi = hi + (bytes[offset + 15 - i] as Field) * v;\n            v = v * 256;\n        }\n        let sig_s = crate::embedded_curve_ops::EmbeddedCurveScalar { lo, hi };\n        sig_s\n    }\n}\n\nimpl Eq for EmbeddedCurveScalar {\n    fn eq(self, other: Self) -> bool {\n        (other.hi == self.hi) & (other.lo == self.lo)\n    }\n}\n\nimpl Hash for EmbeddedCurveScalar {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: crate::hash::Hasher,\n    {\n        self.hi.hash(state);\n        self.lo.hash(state);\n    }\n}\n\n// Computes a multi scalar multiplication over the embedded curve.\n// For bn254, We have Grumpkin and Baby JubJub.\n// For bls12-381, we have JubJub and Bandersnatch.\n//\n// The embedded curve being used is decided by the\n// underlying proof system.\n// docs:start:multi_scalar_mul\npub fn multi_scalar_mul<let N: u32>(\n    points: [EmbeddedCurvePoint; N],\n    scalars: [EmbeddedCurveScalar; N],\n) -> EmbeddedCurvePoint\n// docs:end:multi_scalar_mul\n{\n    multi_scalar_mul_array_return(points, scalars)[0]\n}\n\n#[foreign(multi_scalar_mul)]\npub(crate) fn multi_scalar_mul_array_return<let N: u32>(\n    points: [EmbeddedCurvePoint; N],\n    scalars: [EmbeddedCurveScalar; N],\n) -> [EmbeddedCurvePoint; 1] {}\n\n// docs:start:fixed_base_scalar_mul\npub fn fixed_base_scalar_mul(scalar: EmbeddedCurveScalar) -> EmbeddedCurvePoint\n// docs:end:fixed_base_scalar_mul\n{\n    multi_scalar_mul([EmbeddedCurvePoint::generator()], [scalar])\n}\n\n/// This function only assumes that the points are on the curve\n/// It handles corner cases around the infinity point causing some overhead compared to embedded_curve_add_not_nul and embedded_curve_add_unsafe\n// docs:start:embedded_curve_add\npub fn embedded_curve_add(\n    point1: EmbeddedCurvePoint,\n    point2: EmbeddedCurvePoint,\n) -> EmbeddedCurvePoint {\n    // docs:end:embedded_curve_add\n    if crate::runtime::is_unconstrained() {\n        // `embedded_curve_add_unsafe` requires the inputs not to be the infinity point, so we check it here.\n        // This is because `embedded_curve_add_unsafe` uses the `embedded_curve_add` opcode.\n        // For efficiency, the backend does not check the inputs for the infinity point, but it assumes that they are not the infinity point\n        // so that it can apply the ec addition formula directly.\n        if point1.is_infinite {\n            point2\n        } else if point2.is_infinite {\n            point1\n        } else {\n            embedded_curve_add_unsafe(point1, point2)\n        }\n    } else {\n        // In a constrained context, we also need to check the inputs are not the infinity point because we also use `embedded_curve_add_unsafe`\n        // However we also need to identify the case where the two inputs are the same, because then\n        // the addition formula does not work and we need to use the doubling formula instead.\n        // In unconstrained context, we can check directly if the input values are the same when solving the opcode, so it is not an issue.\n\n        // x_coordinates_match is true if both abscissae are the same\n        let x_coordinates_match = point1.x == point2.x;\n        // y_coordinates_match is true if both ordinates are the same\n        let y_coordinates_match = point1.y == point2.y;\n        // double_predicate is true if both abscissae and ordinates are the same\n        let double_predicate = (x_coordinates_match & y_coordinates_match);\n        // If the abscissae are the same, but not the ordinates, then one point is the opposite of the other\n        let infinity_predicate = (x_coordinates_match & !y_coordinates_match);\n        let point1_1 = EmbeddedCurvePoint {\n            x: point1.x + (x_coordinates_match as Field),\n            y: point1.y,\n            is_infinite: x_coordinates_match,\n        };\n        // point1_1 is guaranteed to have a different abscissa than point2:\n        // - if x_coordinates_match is 0, that means point1.x != point2.x, and point1_1.x = point1.x + 0\n        // - if x_coordinates_match is 1, that means point1.x = point2.x, but point1_1.x = point1.x + 1 in this case\n        // Because the abscissa is different, the addition formula is guaranteed to succeed, so we can safely use `embedded_curve_add_unsafe`\n        // Note that this computation may be garbage: if x_coordinates_match is 1, or if one of the input is the point at infinity.\n        let mut result = embedded_curve_add_unsafe(point1_1, point2);\n\n        // `embedded_curve_add_unsafe` is doing a doubling if the input is the same variable, because in this case it is guaranteed (at 'compile time') that the input is the same.\n        let double = embedded_curve_add_unsafe(point1, point1);\n        // `embedded_curve_add_unsafe` would not perform doubling, even if the inputs point1 and point2 are the same, because it cannot know this without adding some logic (and some constraints)\n        // However we did this logic when we computed `double_predicate`, so we set the result to 2*point1 if point1 and point2 are the same\n        result = if double_predicate { double } else { result };\n\n        // Same logic as above for unconstrained context, we set the proper result when one of the inputs is the infinity point\n        if point1.is_infinite {\n            result = point2;\n        }\n        if point2.is_infinite {\n            result = point1;\n        }\n\n        // Finally, we set the is_infinity flag of the result:\n        // Opposite points should sum into the infinity point, however, if one of them is point at infinity, their coordinates are not meaningful\n        // so we should not use the fact that the inputs are opposite in this case:\n        let mut result_is_infinity =\n            infinity_predicate & (!point1.is_infinite & !point2.is_infinite);\n        // However, if both of them are at infinity, then the result is also at infinity\n        result.is_infinite = result_is_infinity | (point1.is_infinite & point2.is_infinite);\n        result\n    }\n}\n\n#[foreign(embedded_curve_add)]\nfn embedded_curve_add_array_return(\n    _point1: EmbeddedCurvePoint,\n    _point2: EmbeddedCurvePoint,\n) -> [EmbeddedCurvePoint; 1] {}\n\n/// This function assumes that:\n/// The points are on the curve, and\n/// The points don't share an x-coordinate, and\n/// Neither point is the infinity point.\n/// If it is used with correct input, the function ensures the correct non-zero result is returned.\n/// Except for points on the curve, the other assumptions are checked by the function. It will cause assertion failure if they are not respected.\npub fn embedded_curve_add_not_nul(\n    point1: EmbeddedCurvePoint,\n    point2: EmbeddedCurvePoint,\n) -> EmbeddedCurvePoint {\n    assert(point1.x != point2.x);\n    assert(!point1.is_infinite);\n    assert(!point2.is_infinite);\n    embedded_curve_add_unsafe(point1, point2)\n}\n\n/// Unsafe ec addition\n/// If the inputs are the same, it will perform a doubling, but only if point1 and point2 are the same variable.\n/// If they have the same value but are different variables, the result will be incorrect because in this case\n/// it assumes (but does not check) that the points' x-coordinates are not equal.\n/// It also assumes neither point is the infinity point.\npub fn embedded_curve_add_unsafe(\n    point1: EmbeddedCurvePoint,\n    point2: EmbeddedCurvePoint,\n) -> EmbeddedCurvePoint {\n    embedded_curve_add_array_return(point1, point2)[0]\n}\n",
      "path": "std/embedded_curve_ops.nr"
    },
    "17": {
      "source": "use crate::field::field_less_than;\nuse crate::runtime::is_unconstrained;\n\n// The low and high decomposition of the field modulus\nglobal PLO: Field = 53438638232309528389504892708671455233;\nglobal PHI: Field = 64323764613183177041862057485226039389;\n\npub(crate) global TWO_POW_128: Field = 0x100000000000000000000000000000000;\n\n// Decomposes a single field into two 16 byte fields.\nfn compute_decomposition(x: Field) -> (Field, Field) {\n    // Here's we're taking advantage of truncating 128 bit limbs from the input field\n    // and then subtracting them from the input such the field division is equivalent to integer division.\n    let low = (x as u128) as Field;\n    let high = (x - low) / TWO_POW_128;\n\n    (low, high)\n}\n\npub(crate) unconstrained fn decompose_hint(x: Field) -> (Field, Field) {\n    compute_decomposition(x)\n}\n\nunconstrained fn lte_hint(x: Field, y: Field) -> bool {\n    if x == y {\n        true\n    } else {\n        field_less_than(x, y)\n    }\n}\n\n// Assert that (alo > blo && ahi >= bhi) || (alo <= blo && ahi > bhi)\nfn assert_gt_limbs(a: (Field, Field), b: (Field, Field)) {\n    let (alo, ahi) = a;\n    let (blo, bhi) = b;\n    // Safety: borrow is enforced to be boolean due to its type.\n    // if borrow is 0, it asserts that (alo > blo && ahi >= bhi)\n    // if borrow is 1, it asserts that (alo <= blo && ahi > bhi)\n    unsafe {\n        let borrow = lte_hint(alo, blo);\n\n        let rlo = alo - blo - 1 + (borrow as Field) * TWO_POW_128;\n        let rhi = ahi - bhi - (borrow as Field);\n\n        rlo.assert_max_bit_size::<128>();\n        rhi.assert_max_bit_size::<128>();\n    }\n}\n\n/// Decompose a single field into two 16 byte fields.\npub fn decompose(x: Field) -> (Field, Field) {\n    if is_unconstrained() {\n        compute_decomposition(x)\n    } else {\n        // Safety: decomposition is properly checked below\n        unsafe {\n            // Take hints of the decomposition\n            let (xlo, xhi) = decompose_hint(x);\n\n            // Range check the limbs\n            xlo.assert_max_bit_size::<128>();\n            xhi.assert_max_bit_size::<128>();\n\n            // Check that the decomposition is correct\n            assert_eq(x, xlo + TWO_POW_128 * xhi);\n\n            // Assert that the decomposition of P is greater than the decomposition of x\n            assert_gt_limbs((PLO, PHI), (xlo, xhi));\n            (xlo, xhi)\n        }\n    }\n}\n\npub fn assert_gt(a: Field, b: Field) {\n    if is_unconstrained() {\n        assert(\n            // Safety: already unconstrained\n            unsafe { field_less_than(b, a) },\n        );\n    } else {\n        // Decompose a and b\n        let a_limbs = decompose(a);\n        let b_limbs = decompose(b);\n\n        // Assert that a_limbs is greater than b_limbs\n        assert_gt_limbs(a_limbs, b_limbs)\n    }\n}\n\npub fn assert_lt(a: Field, b: Field) {\n    assert_gt(b, a);\n}\n\npub fn gt(a: Field, b: Field) -> bool {\n    if is_unconstrained() {\n        // Safety: unsafe in unconstrained\n        unsafe {\n            field_less_than(b, a)\n        }\n    } else if a == b {\n        false\n    } else {\n        // Safety: Take a hint of the comparison and verify it\n        unsafe {\n            if field_less_than(a, b) {\n                assert_gt(b, a);\n                false\n            } else {\n                assert_gt(a, b);\n                true\n            }\n        }\n    }\n}\n\npub fn lt(a: Field, b: Field) -> bool {\n    gt(b, a)\n}\n\nmod tests {\n    // TODO: Allow imports from \"super\"\n    use crate::field::bn254::{assert_gt, decompose, gt, lte_hint, PHI, PLO, TWO_POW_128};\n\n    #[test]\n    fn check_decompose() {\n        assert_eq(decompose(TWO_POW_128), (0, 1));\n        assert_eq(decompose(TWO_POW_128 + 0x1234567890), (0x1234567890, 1));\n        assert_eq(decompose(0x1234567890), (0x1234567890, 0));\n    }\n\n    #[test]\n    unconstrained fn check_decompose_unconstrained() {\n        assert_eq(decompose(TWO_POW_128), (0, 1));\n        assert_eq(decompose(TWO_POW_128 + 0x1234567890), (0x1234567890, 1));\n        assert_eq(decompose(0x1234567890), (0x1234567890, 0));\n    }\n\n    #[test]\n    unconstrained fn check_lte_hint() {\n        assert(lte_hint(0, 1));\n        assert(lte_hint(0, 0x100));\n        assert(lte_hint(0x100, TWO_POW_128 - 1));\n        assert(!lte_hint(0 - 1, 0));\n\n        assert(lte_hint(0, 0));\n        assert(lte_hint(0x100, 0x100));\n        assert(lte_hint(0 - 1, 0 - 1));\n    }\n\n    #[test]\n    fn check_assert_gt() {\n        assert_gt(1, 0);\n        assert_gt(0x100, 0);\n        assert_gt((0 - 1), (0 - 2));\n        assert_gt(TWO_POW_128, 0);\n        assert_gt(0 - 1, 0);\n    }\n\n    #[test]\n    unconstrained fn check_assert_gt_unconstrained() {\n        assert_gt(1, 0);\n        assert_gt(0x100, 0);\n        assert_gt((0 - 1), (0 - 2));\n        assert_gt(TWO_POW_128, 0);\n        assert_gt(0 - 1, 0);\n    }\n\n    #[test]\n    fn check_gt() {\n        assert(gt(1, 0));\n        assert(gt(0x100, 0));\n        assert(gt((0 - 1), (0 - 2)));\n        assert(gt(TWO_POW_128, 0));\n        assert(!gt(0, 0));\n        assert(!gt(0, 0x100));\n        assert(gt(0 - 1, 0 - 2));\n        assert(!gt(0 - 2, 0 - 1));\n    }\n\n    #[test]\n    unconstrained fn check_gt_unconstrained() {\n        assert(gt(1, 0));\n        assert(gt(0x100, 0));\n        assert(gt((0 - 1), (0 - 2)));\n        assert(gt(TWO_POW_128, 0));\n        assert(!gt(0, 0));\n        assert(!gt(0, 0x100));\n        assert(gt(0 - 1, 0 - 2));\n        assert(!gt(0 - 2, 0 - 1));\n    }\n\n    #[test]\n    fn check_plo_phi() {\n        assert_eq(PLO + PHI * TWO_POW_128, 0);\n        let p_bytes = crate::field::modulus_le_bytes();\n        let mut p_low: Field = 0;\n        let mut p_high: Field = 0;\n\n        let mut offset = 1;\n        for i in 0..16 {\n            p_low += (p_bytes[i] as Field) * offset;\n            p_high += (p_bytes[i + 16] as Field) * offset;\n            offset *= 256;\n        }\n        assert_eq(p_low, PLO);\n        assert_eq(p_high, PHI);\n    }\n}\n",
      "path": "std/field/bn254.nr"
    },
    "19": {
      "source": "// Exposed only for usage in `std::meta`\npub(crate) mod poseidon2;\n\nuse crate::default::Default;\nuse crate::embedded_curve_ops::{\n    EmbeddedCurvePoint, EmbeddedCurveScalar, multi_scalar_mul, multi_scalar_mul_array_return,\n};\nuse crate::meta::derive_via;\n\n#[foreign(sha256_compression)]\n// docs:start:sha256_compression\npub fn sha256_compression(input: [u32; 16], state: [u32; 8]) -> [u32; 8] {}\n// docs:end:sha256_compression\n\n#[foreign(keccakf1600)]\n// docs:start:keccakf1600\npub fn keccakf1600(input: [u64; 25]) -> [u64; 25] {}\n// docs:end:keccakf1600\n\npub mod keccak {\n    #[deprecated(\"This function has been moved to std::hash::keccakf1600\")]\n    pub fn keccakf1600(input: [u64; 25]) -> [u64; 25] {\n        super::keccakf1600(input)\n    }\n}\n\n#[foreign(blake2s)]\n// docs:start:blake2s\npub fn blake2s<let N: u32>(input: [u8; N]) -> [u8; 32]\n// docs:end:blake2s\n{}\n\n#[foreign(blake3)]\n// docs:start:blake3\npub fn blake3<let N: u32>(input: [u8; N]) -> [u8; 32]\n// docs:end:blake3\n{}\n\n// docs:start:pedersen_commitment\npub fn pedersen_commitment<let N: u32>(input: [Field; N]) -> EmbeddedCurvePoint {\n    // docs:end:pedersen_commitment\n    pedersen_commitment_with_separator(input, 0)\n}\n\n#[inline_always]\npub fn pedersen_commitment_with_separator<let N: u32>(\n    input: [Field; N],\n    separator: u32,\n) -> EmbeddedCurvePoint {\n    let mut points = [EmbeddedCurveScalar { lo: 0, hi: 0 }; N];\n    for i in 0..N {\n        // we use the unsafe version because the multi_scalar_mul will constrain the scalars.\n        points[i] = from_field_unsafe(input[i]);\n    }\n    let generators = derive_generators(\"DEFAULT_DOMAIN_SEPARATOR\".as_bytes(), separator);\n    multi_scalar_mul(generators, points)\n}\n\n// docs:start:pedersen_hash\npub fn pedersen_hash<let N: u32>(input: [Field; N]) -> Field\n// docs:end:pedersen_hash\n{\n    pedersen_hash_with_separator(input, 0)\n}\n\n#[no_predicates]\npub fn pedersen_hash_with_separator<let N: u32>(input: [Field; N], separator: u32) -> Field {\n    let mut scalars: [EmbeddedCurveScalar; N + 1] = [EmbeddedCurveScalar { lo: 0, hi: 0 }; N + 1];\n    let mut generators: [EmbeddedCurvePoint; N + 1] =\n        [EmbeddedCurvePoint::point_at_infinity(); N + 1];\n    let domain_generators: [EmbeddedCurvePoint; N] =\n        derive_generators(\"DEFAULT_DOMAIN_SEPARATOR\".as_bytes(), separator);\n\n    for i in 0..N {\n        scalars[i] = from_field_unsafe(input[i]);\n        generators[i] = domain_generators[i];\n    }\n    scalars[N] = EmbeddedCurveScalar { lo: N as Field, hi: 0 as Field };\n\n    let length_generator: [EmbeddedCurvePoint; 1] =\n        derive_generators(\"pedersen_hash_length\".as_bytes(), 0);\n    generators[N] = length_generator[0];\n    multi_scalar_mul_array_return(generators, scalars)[0].x\n}\n\n#[field(bn254)]\n#[inline_always]\npub fn derive_generators<let N: u32, let M: u32>(\n    domain_separator_bytes: [u8; M],\n    starting_index: u32,\n) -> [EmbeddedCurvePoint; N] {\n    crate::assert_constant(domain_separator_bytes);\n    // TODO(https://github.com/noir-lang/noir/issues/5672): Add back assert_constant on starting_index\n    __derive_generators(domain_separator_bytes, starting_index)\n}\n\n#[builtin(derive_pedersen_generators)]\n#[field(bn254)]\nfn __derive_generators<let N: u32, let M: u32>(\n    domain_separator_bytes: [u8; M],\n    starting_index: u32,\n) -> [EmbeddedCurvePoint; N] {}\n\n#[field(bn254)]\n// Same as from_field but:\n// does not assert the limbs are 128 bits\n// does not assert the decomposition does not overflow the EmbeddedCurveScalar\nfn from_field_unsafe(scalar: Field) -> EmbeddedCurveScalar {\n    // Safety: xlo and xhi decomposition is checked below\n    let (xlo, xhi) = unsafe { crate::field::bn254::decompose_hint(scalar) };\n    // Check that the decomposition is correct\n    assert_eq(scalar, xlo + crate::field::bn254::TWO_POW_128 * xhi);\n    EmbeddedCurveScalar { lo: xlo, hi: xhi }\n}\n\npub fn hash_to_field(inputs: [Field]) -> Field {\n    let mut sum = 0;\n\n    for input in inputs {\n        let input_bytes: [u8; 32] = input.to_le_bytes();\n        sum += crate::field::bytes32_to_field(blake2s(input_bytes));\n    }\n\n    sum\n}\n\n#[foreign(poseidon2_permutation)]\npub fn poseidon2_permutation<let N: u32>(_input: [Field; N], _state_length: u32) -> [Field; N] {}\n\n// Generic hashing support.\n// Partially ported and impacted by rust.\n\n// Hash trait shall be implemented per type.\n#[derive_via(derive_hash)]\npub trait Hash {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher;\n}\n\n// docs:start:derive_hash\ncomptime fn derive_hash(s: TypeDefinition) -> Quoted {\n    let name = quote { Hash };\n    let signature = quote { fn hash<H>(_self: Self, _state: &mut H) where H: std::hash::Hasher };\n    let for_each_field = |name| quote { _self.$name.hash(_state); };\n    crate::meta::make_trait_impl(\n        s,\n        name,\n        signature,\n        for_each_field,\n        quote {},\n        |fields| fields,\n    )\n}\n// docs:end:derive_hash\n\n// Hasher trait shall be implemented by algorithms to provide hash-agnostic means.\n// TODO: consider making the types generic here ([u8], [Field], etc.)\npub trait Hasher {\n    fn finish(self) -> Field;\n\n    fn write(&mut self, input: Field);\n}\n\n// BuildHasher is a factory trait, responsible for production of specific Hasher.\npub trait BuildHasher<H>\nwhere\n    H: Hasher,\n{\n    fn build_hasher(self) -> H;\n}\n\npub struct BuildHasherDefault<H>;\n\nimpl<H> BuildHasher<H> for BuildHasherDefault<H>\nwhere\n    H: Hasher + Default,\n{\n    fn build_hasher(_self: Self) -> H {\n        H::default()\n    }\n}\n\nimpl<H> Default for BuildHasherDefault<H>\nwhere\n    H: Hasher + Default,\n{\n    fn default() -> Self {\n        BuildHasherDefault {}\n    }\n}\n\nimpl Hash for Field {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self);\n    }\n}\n\nimpl Hash for u1 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u8 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u16 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u32 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u64 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u128 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for i8 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for i16 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for i32 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for i64 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for bool {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for () {\n    fn hash<H>(_self: Self, _state: &mut H)\n    where\n        H: Hasher,\n    {}\n}\n\nimpl<T, let N: u32> Hash for [T; N]\nwhere\n    T: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        for elem in self {\n            elem.hash(state);\n        }\n    }\n}\n\nimpl<T> Hash for [T]\nwhere\n    T: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.len().hash(state);\n        for elem in self {\n            elem.hash(state);\n        }\n    }\n}\n\nimpl<A, B> Hash for (A, B)\nwhere\n    A: Hash,\n    B: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.0.hash(state);\n        self.1.hash(state);\n    }\n}\n\nimpl<A, B, C> Hash for (A, B, C)\nwhere\n    A: Hash,\n    B: Hash,\n    C: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.0.hash(state);\n        self.1.hash(state);\n        self.2.hash(state);\n    }\n}\n\nimpl<A, B, C, D> Hash for (A, B, C, D)\nwhere\n    A: Hash,\n    B: Hash,\n    C: Hash,\n    D: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.0.hash(state);\n        self.1.hash(state);\n        self.2.hash(state);\n        self.3.hash(state);\n    }\n}\n\nimpl<A, B, C, D, E> Hash for (A, B, C, D, E)\nwhere\n    A: Hash,\n    B: Hash,\n    C: Hash,\n    D: Hash,\n    E: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.0.hash(state);\n        self.1.hash(state);\n        self.2.hash(state);\n        self.3.hash(state);\n        self.4.hash(state);\n    }\n}\n\n// Some test vectors for Pedersen hash and Pedersen Commitment.\n// They have been generated using the same functions so the tests are for now useless\n// but they will be useful when we switch to Noir implementation.\n#[test]\nfn assert_pedersen() {\n    assert_eq(\n        pedersen_hash_with_separator([1], 1),\n        0x1b3f4b1a83092a13d8d1a59f7acb62aba15e7002f4440f2275edb99ebbc2305f,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1], 1),\n        EmbeddedCurvePoint {\n            x: 0x054aa86a73cb8a34525e5bbed6e43ba1198e860f5f3950268f71df4591bde402,\n            y: 0x209dcfbf2cfb57f9f6046f44d71ac6faf87254afc7407c04eb621a6287cac126,\n            is_infinite: false,\n        },\n    );\n\n    assert_eq(\n        pedersen_hash_with_separator([1, 2], 2),\n        0x26691c129448e9ace0c66d11f0a16d9014a9e8498ee78f4d69f0083168188255,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2], 2),\n        EmbeddedCurvePoint {\n            x: 0x2e2b3b191e49541fe468ec6877721d445dcaffe41728df0a0eafeb15e87b0753,\n            y: 0x2ff4482400ad3a6228be17a2af33e2bcdf41be04795f9782bd96efe7e24f8778,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3], 3),\n        0x0bc694b7a1f8d10d2d8987d07433f26bd616a2d351bc79a3c540d85b6206dbe4,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3], 3),\n        EmbeddedCurvePoint {\n            x: 0x1fee4e8cf8d2f527caa2684236b07c4b1bad7342c01b0f75e9a877a71827dc85,\n            y: 0x2f9fedb9a090697ab69bf04c8bc15f7385b3e4b68c849c1536e5ae15ff138fd1,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4], 4),\n        0xdae10fb32a8408521803905981a2b300d6a35e40e798743e9322b223a5eddc,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4], 4),\n        EmbeddedCurvePoint {\n            x: 0x07ae3e202811e1fca39c2d81eabe6f79183978e6f12be0d3b8eda095b79bdbc9,\n            y: 0x0afc6f892593db6fbba60f2da558517e279e0ae04f95758587760ba193145014,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5], 5),\n        0xfc375b062c4f4f0150f7100dfb8d9b72a6d28582dd9512390b0497cdad9c22,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5], 5),\n        EmbeddedCurvePoint {\n            x: 0x1754b12bd475a6984a1094b5109eeca9838f4f81ac89c5f0a41dbce53189bb29,\n            y: 0x2da030e3cfcdc7ddad80eaf2599df6692cae0717d4e9f7bfbee8d073d5d278f7,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6], 6),\n        0x1696ed13dc2730062a98ac9d8f9de0661bb98829c7582f699d0273b18c86a572,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6], 6),\n        EmbeddedCurvePoint {\n            x: 0x190f6c0e97ad83e1e28da22a98aae156da083c5a4100e929b77e750d3106a697,\n            y: 0x1f4b60f34ef91221a0b49756fa0705da93311a61af73d37a0c458877706616fb,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7], 7),\n        0x128c0ff144fc66b6cb60eeac8a38e23da52992fc427b92397a7dffd71c45ede3,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7], 7),\n        EmbeddedCurvePoint {\n            x: 0x015441e9d29491b06563fac16fc76abf7a9534c715421d0de85d20dbe2965939,\n            y: 0x1d2575b0276f4e9087e6e07c2cb75aa1baafad127af4be5918ef8a2ef2fea8fc,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7, 8], 8),\n        0x2f960e117482044dfc99d12fece2ef6862fba9242be4846c7c9a3e854325a55c,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7, 8], 8),\n        EmbeddedCurvePoint {\n            x: 0x1657737676968887fceb6dd516382ea13b3a2c557f509811cd86d5d1199bc443,\n            y: 0x1f39f0cb569040105fa1e2f156521e8b8e08261e635a2b210bdc94e8d6d65f77,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9], 9),\n        0x0c96db0790602dcb166cc4699e2d306c479a76926b81c2cb2aaa92d249ec7be7,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9], 9),\n        EmbeddedCurvePoint {\n            x: 0x0a3ceae42d14914a432aa60ec7fded4af7dad7dd4acdbf2908452675ec67e06d,\n            y: 0xfc19761eaaf621ad4aec9a8b2e84a4eceffdba78f60f8b9391b0bd9345a2f2,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 10),\n        0x2cd37505871bc460a62ea1e63c7fe51149df5d0801302cf1cbc48beb8dff7e94,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 10),\n        EmbeddedCurvePoint {\n            x: 0x2fb3f8b3d41ddde007c8c3c62550f9a9380ee546fcc639ffbb3fd30c8d8de30c,\n            y: 0x300783be23c446b11a4c0fabf6c91af148937cea15fcf5fb054abf7f752ee245,\n            is_infinite: false,\n        },\n    );\n}\n",
      "path": "std/hash/mod.nr"
    },
    "50": {
      "source": "fn main(x: Field, y: Field, salt: Field, out_x: Field, out_y: Field, out_hash: Field) {\n    let res = std::hash::pedersen_commitment([x, y]);\n    assert(res.x == out_x);\n    assert(res.y == out_y);\n\n    let res_hash = std::hash::pedersen_hash_with_separator([x, y], 0);\n    assert_eq(res_hash, out_hash);\n\n    assert(res_hash != res.x);\n\n    let raw_data = [x, y];\n    let mut state = 0;\n    for i in 0..2 {\n        state = state * 8 + raw_data[i];\n    }\n    state += salt;\n    let hash = std::hash::pedersen_commitment([state]);\n    assert(std::hash::pedersen_commitment([43]).x == hash.x);\n}\n",
      "path": ""
    }
  },
  "names": [
    "main"
  ],
  "brillig_names": [
    "main"
  ]
}
