---
source: tooling/nargo_cli/tests/execute.rs
expression: artifact
---
{
  "noir_version": "[noir_version]",
  "hash": "[hash]",
  "abi": {
    "parameters": [
      {
        "name": "old_root",
        "type": {
          "kind": "field"
        },
        "visibility": "private"
      },
      {
        "name": "old_leaf",
        "type": {
          "kind": "field"
        },
        "visibility": "private"
      },
      {
        "name": "old_hash_path",
        "type": {
          "kind": "array",
          "length": 3,
          "type": {
            "kind": "field"
          }
        },
        "visibility": "private"
      },
      {
        "name": "new_root",
        "type": {
          "kind": "field"
        },
        "visibility": "public"
      },
      {
        "name": "leaf",
        "type": {
          "kind": "field"
        },
        "visibility": "private"
      },
      {
        "name": "index",
        "type": {
          "kind": "field"
        },
        "visibility": "private"
      }
    ],
    "return_type": null,
    "error_types": {
      "17843811134343075018": {
        "error_kind": "string",
        "string": "Stack too deep"
      }
    }
  },
  "bytecode": [
    "func 0",
    "current witness index : _71",
    "private parameters indices : [_0, _1, _2, _3, _4, _6, _7]",
    "public parameters indices : [_5]",
    "return value indices : []",
    "BRILLIG CALL func 1: inputs: [Single(Expression { mul_terms: [], linear_combinations: [(1, Witness(7))], q_c: 0 }), Single(Expression { mul_terms: [], linear_combinations: [], q_c: 3 }), Single(Expression { mul_terms: [], linear_combinations: [], q_c: 2 })], outputs: [Array([Witness(8), Witness(9), Witness(10)])]",
    "BLACKBOX::RANGE [(_8, 1)] []",
    "BLACKBOX::RANGE [(_9, 1)] []",
    "BLACKBOX::RANGE [(_10, 1)] []",
    "EXPR [ (1, _7) (-1, _8) (-2, _9) (-4, _10) 0 ]",
    "BRILLIG CALL func 0: inputs: [Single(Expression { mul_terms: [(-1, Witness(8), Witness(1)), (1, Witness(8), Witness(2))], linear_combinations: [(1, Witness(1))], q_c: 0 })], outputs: [Simple(Witness(11)), Simple(Witness(12))]",
    "EXPR [ (-1, _1, _8) (-1, _53) 0 ]",
    "EXPR [ (1, _2, _8) (-1, _54) 0 ]",
    "EXPR [ (1, _1) (-1, _11) (-340282366920938463463374607431768211456, _12) (1, _53) (1, _54) 0 ]",
    "BRILLIG CALL func 0: inputs: [Single(Expression { mul_terms: [(1, Witness(8), Witness(1)), (-1, Witness(8), Witness(2))], linear_combinations: [(1, Witness(2))], q_c: 0 })], outputs: [Simple(Witness(13)), Simple(Witness(14))]",
    "EXPR [ (1, _2) (-1, _13) (-340282366920938463463374607431768211456, _14) (-1, _53) (-1, _54) 0 ]",
    "BLACKBOX::MULTI_SCALAR_MUL [(3728882899078719075161482178784387565366481897740339799480980287259621149274, 254), (-9903063709032878667290627648209915537972247634463802596148419711785767431332, 254), (0, 1), (2393473289045184898987089634332637236754766663897650125720167164137088869378, 254), (-7135402912423807765050323395026152633898511180575289670895350565966806597339, 254), (0, 1), (-1094708040843609169356775910874053498301840173462935739639689208799068762676, 254), (-718703907181967287621274717949248537252263842169639534402461291799004475262, 254), (0, 1), (_11, 254), (_12, 254), (_13, 254), (_14, 254), (2, 254), (0, 254)] [_15, _16, _17]",
    "BRILLIG CALL func 0: inputs: [Single(Expression { mul_terms: [(1, Witness(9), Witness(3)), (-1, Witness(9), Witness(15))], linear_combinations: [(1, Witness(15))], q_c: 0 })], outputs: [Simple(Witness(18)), Simple(Witness(19))]",
    "EXPR [ (1, _3, _9) (-1, _57) 0 ]",
    "EXPR [ (-1, _9, _15) (-1, _58) 0 ]",
    "EXPR [ (1, _15) (-1, _18) (-340282366920938463463374607431768211456, _19) (1, _57) (1, _58) 0 ]",
    "BRILLIG CALL func 0: inputs: [Single(Expression { mul_terms: [(-1, Witness(9), Witness(3)), (1, Witness(9), Witness(15))], linear_combinations: [(1, Witness(3))], q_c: 0 })], outputs: [Simple(Witness(20)), Simple(Witness(21))]",
    "EXPR [ (1, _3) (-1, _20) (-340282366920938463463374607431768211456, _21) (-1, _57) (-1, _58) 0 ]",
    "BLACKBOX::MULTI_SCALAR_MUL [(3728882899078719075161482178784387565366481897740339799480980287259621149274, 254), (-9903063709032878667290627648209915537972247634463802596148419711785767431332, 254), (0, 1), (2393473289045184898987089634332637236754766663897650125720167164137088869378, 254), (-7135402912423807765050323395026152633898511180575289670895350565966806597339, 254), (0, 1), (-1094708040843609169356775910874053498301840173462935739639689208799068762676, 254), (-718703907181967287621274717949248537252263842169639534402461291799004475262, 254), (0, 1), (_18, 254), (_19, 254), (_20, 254), (_21, 254), (2, 254), (0, 254)] [_22, _23, _24]",
    "BRILLIG CALL func 0: inputs: [Single(Expression { mul_terms: [(1, Witness(10), Witness(4)), (-1, Witness(10), Witness(22))], linear_combinations: [(1, Witness(22))], q_c: 0 })], outputs: [Simple(Witness(25)), Simple(Witness(26))]",
    "EXPR [ (1, _4, _10) (-1, _61) 0 ]",
    "EXPR [ (-1, _10, _22) (-1, _62) 0 ]",
    "EXPR [ (1, _22) (-1, _25) (-340282366920938463463374607431768211456, _26) (1, _61) (1, _62) 0 ]",
    "BRILLIG CALL func 0: inputs: [Single(Expression { mul_terms: [(-1, Witness(10), Witness(4)), (1, Witness(10), Witness(22))], linear_combinations: [(1, Witness(4))], q_c: 0 })], outputs: [Simple(Witness(27)), Simple(Witness(28))]",
    "EXPR [ (1, _4) (-1, _27) (-340282366920938463463374607431768211456, _28) (-1, _61) (-1, _62) 0 ]",
    "BLACKBOX::MULTI_SCALAR_MUL [(3728882899078719075161482178784387565366481897740339799480980287259621149274, 254), (-9903063709032878667290627648209915537972247634463802596148419711785767431332, 254), (0, 1), (2393473289045184898987089634332637236754766663897650125720167164137088869378, 254), (-7135402912423807765050323395026152633898511180575289670895350565966806597339, 254), (0, 1), (-1094708040843609169356775910874053498301840173462935739639689208799068762676, 254), (-718703907181967287621274717949248537252263842169639534402461291799004475262, 254), (0, 1), (_25, 254), (_26, 254), (_27, 254), (_28, 254), (2, 254), (0, 254)] [_29, _30, _31]",
    "EXPR [ (1, _0) (-1, _29) 0 ]",
    "BRILLIG CALL func 0: inputs: [Single(Expression { mul_terms: [(1, Witness(8), Witness(2)), (-1, Witness(8), Witness(6))], linear_combinations: [(1, Witness(6))], q_c: 0 })], outputs: [Simple(Witness(32)), Simple(Witness(33))]",
    "EXPR [ (-1, _6, _8) (-1, _65) 0 ]",
    "EXPR [ (1, _6) (-1, _32) (-340282366920938463463374607431768211456, _33) (1, _54) (1, _65) 0 ]",
    "BRILLIG CALL func 0: inputs: [Single(Expression { mul_terms: [(-1, Witness(8), Witness(2)), (1, Witness(8), Witness(6))], linear_combinations: [(1, Witness(2))], q_c: 0 })], outputs: [Simple(Witness(34)), Simple(Witness(35))]",
    "EXPR [ (1, _2) (-1, _34) (-340282366920938463463374607431768211456, _35) (-1, _54) (-1, _65) 0 ]",
    "BLACKBOX::MULTI_SCALAR_MUL [(3728882899078719075161482178784387565366481897740339799480980287259621149274, 254), (-9903063709032878667290627648209915537972247634463802596148419711785767431332, 254), (0, 1), (2393473289045184898987089634332637236754766663897650125720167164137088869378, 254), (-7135402912423807765050323395026152633898511180575289670895350565966806597339, 254), (0, 1), (-1094708040843609169356775910874053498301840173462935739639689208799068762676, 254), (-718703907181967287621274717949248537252263842169639534402461291799004475262, 254), (0, 1), (_32, 254), (_33, 254), (_34, 254), (_35, 254), (2, 254), (0, 254)] [_36, _37, _38]",
    "BRILLIG CALL func 0: inputs: [Single(Expression { mul_terms: [(1, Witness(9), Witness(3)), (-1, Witness(9), Witness(36))], linear_combinations: [(1, Witness(36))], q_c: 0 })], outputs: [Simple(Witness(39)), Simple(Witness(40))]",
    "EXPR [ (-1, _9, _36) (-1, _68) 0 ]",
    "EXPR [ (1, _36) (-1, _39) (-340282366920938463463374607431768211456, _40) (1, _57) (1, _68) 0 ]",
    "BRILLIG CALL func 0: inputs: [Single(Expression { mul_terms: [(-1, Witness(9), Witness(3)), (1, Witness(9), Witness(36))], linear_combinations: [(1, Witness(3))], q_c: 0 })], outputs: [Simple(Witness(41)), Simple(Witness(42))]",
    "EXPR [ (1, _3) (-1, _41) (-340282366920938463463374607431768211456, _42) (-1, _57) (-1, _68) 0 ]",
    "BLACKBOX::MULTI_SCALAR_MUL [(3728882899078719075161482178784387565366481897740339799480980287259621149274, 254), (-9903063709032878667290627648209915537972247634463802596148419711785767431332, 254), (0, 1), (2393473289045184898987089634332637236754766663897650125720167164137088869378, 254), (-7135402912423807765050323395026152633898511180575289670895350565966806597339, 254), (0, 1), (-1094708040843609169356775910874053498301840173462935739639689208799068762676, 254), (-718703907181967287621274717949248537252263842169639534402461291799004475262, 254), (0, 1), (_39, 254), (_40, 254), (_41, 254), (_42, 254), (2, 254), (0, 254)] [_43, _44, _45]",
    "BRILLIG CALL func 0: inputs: [Single(Expression { mul_terms: [(1, Witness(10), Witness(4)), (-1, Witness(10), Witness(43))], linear_combinations: [(1, Witness(43))], q_c: 0 })], outputs: [Simple(Witness(46)), Simple(Witness(47))]",
    "EXPR [ (-1, _10, _43) (-1, _71) 0 ]",
    "EXPR [ (1, _43) (-1, _46) (-340282366920938463463374607431768211456, _47) (1, _61) (1, _71) 0 ]",
    "BRILLIG CALL func 0: inputs: [Single(Expression { mul_terms: [(-1, Witness(10), Witness(4)), (1, Witness(10), Witness(43))], linear_combinations: [(1, Witness(4))], q_c: 0 })], outputs: [Simple(Witness(48)), Simple(Witness(49))]",
    "EXPR [ (1, _4) (-1, _48) (-340282366920938463463374607431768211456, _49) (-1, _61) (-1, _71) 0 ]",
    "BLACKBOX::MULTI_SCALAR_MUL [(3728882899078719075161482178784387565366481897740339799480980287259621149274, 254), (-9903063709032878667290627648209915537972247634463802596148419711785767431332, 254), (0, 1), (2393473289045184898987089634332637236754766663897650125720167164137088869378, 254), (-7135402912423807765050323395026152633898511180575289670895350565966806597339, 254), (0, 1), (-1094708040843609169356775910874053498301840173462935739639689208799068762676, 254), (-718703907181967287621274717949248537252263842169639534402461291799004475262, 254), (0, 1), (_46, 254), (_47, 254), (_48, 254), (_49, 254), (2, 254), (0, 254)] [_50, _51, _52]",
    "EXPR [ (1, _5) (-1, _50) 0 ]",
    "unconstrained func 0",
    "[Const { destination: Direct(2), bit_size: Integer(U32), value: 1 }, Const { destination: Direct(1), bit_size: Integer(U32), value: 32839 }, Const { destination: Direct(0), bit_size: Integer(U32), value: 3 }, Const { destination: Relative(2), bit_size: Integer(U32), value: 1 }, Const { destination: Relative(3), bit_size: Integer(U32), value: 0 }, CalldataCopy { destination_address: Direct(32836), size_address: Relative(2), offset_address: Relative(3) }, Mov { destination: Relative(1), source: Direct(32836) }, Call { location: 14 }, Call { location: 15 }, Mov { destination: Direct(32837), source: Relative(1) }, Mov { destination: Direct(32838), source: Relative(2) }, Const { destination: Relative(3), bit_size: Integer(U32), value: 32837 }, Const { destination: Relative(4), bit_size: Integer(U32), value: 2 }, Stop { return_data: HeapVector { pointer: Relative(3), size: Relative(4) } }, Return, Call { location: 24 }, Cast { destination: Relative(3), source: Relative(1), bit_size: Integer(U128) }, Cast { destination: Relative(2), source: Relative(3), bit_size: Field }, BinaryFieldOp { destination: Relative(3), op: Sub, lhs: Relative(1), rhs: Relative(2) }, Const { destination: Relative(1), bit_size: Field, value: 8680525429001239497728366687280168587232520577698044359798894838135247199343 }, BinaryFieldOp { destination: Relative(4), op: Mul, lhs: Relative(3), rhs: Relative(1) }, Mov { destination: Relative(1), source: Relative(2) }, Mov { destination: Relative(2), source: Relative(4) }, Return, Const { destination: Direct(32772), bit_size: Integer(U32), value: 30720 }, BinaryIntOp { destination: Direct(32771), op: LessThan, bit_size: U32, lhs: Direct(0), rhs: Direct(32772) }, JumpIf { condition: Direct(32771), location: 29 }, IndirectConst { destination_pointer: Direct(1), bit_size: Integer(U64), value: 17843811134343075018 }, Trap { revert_data: HeapVector { pointer: Direct(1), size: Direct(2) } }, Return]",
    "unconstrained func 1",
    "[Const { destination: Direct(5), bit_size: Integer(U32), value: 0 }, Const { destination: Direct(6), bit_size: Integer(U32), value: 1 }, Const { destination: Direct(7), bit_size: Integer(U32), value: 3 }, CalldataCopy { destination_address: Direct(0), size_address: Direct(7), offset_address: Direct(5) }, Cast { destination: Direct(1), source: Direct(1), bit_size: Integer(U32) }, Const { destination: Direct(9), bit_size: Integer(U32), value: 10 }, BinaryIntOp { destination: Direct(7), op: Add, bit_size: U32, lhs: Direct(9), rhs: Direct(1) }, BinaryFieldOp { destination: Direct(3), op: IntegerDiv, lhs: Direct(0), rhs: Direct(2) }, BinaryFieldOp { destination: Direct(4), op: Mul, lhs: Direct(3), rhs: Direct(2) }, BinaryFieldOp { destination: Direct(4), op: Sub, lhs: Direct(0), rhs: Direct(4) }, Store { destination_pointer: Direct(9), source: Direct(4) }, BinaryIntOp { destination: Direct(9), op: Add, bit_size: U32, lhs: Direct(9), rhs: Direct(6) }, Mov { destination: Direct(0), source: Direct(3) }, BinaryIntOp { destination: Direct(8), op: LessThan, bit_size: U32, lhs: Direct(9), rhs: Direct(7) }, JumpIf { condition: Direct(8), location: 7 }, Const { destination: Direct(9), bit_size: Integer(U32), value: 10 }, Stop { return_data: HeapVector { pointer: Direct(9), size: Direct(1) } }]"
  ],
  "debug_symbols": "pZbdbvIwDIbvJcc9aGznp9zKNKEC3VSpKqiDSZ8Q9/4ljVNAU6KoPYmJk/dp47jGd3HqDrfvfT9+nX/E7uMuDlM/DP33fjgf22t/Hp33Lmo/SC12UAlpgrFih840YkeVALeDHo9KRNn+OnWdV71wHP3STt14FbvxNgyV+G2H27zp59KOs722k1utK9GNJ2cd8KsfOv/rUT3VdVpqa2CxBb3IpXnTy7ReE7FeK1yjtzLqrV2lj4c3dfL5mfNL3bAe4Bk+9R4/ldbToierUnqdeT4sAZSg4XkCW/oGSscIKIMrTqDJxhvQayJg5HIDAGv0CmMG1km9zKSAtBDfQFr1kkTNOwLSCEClYxqgxSQC0wjUFDMZtaVVCKNjKNDWch1Cmc0IakoQuXDSEgsgtQ6hMRYm0KTWIUwMJxjA7QidQuTqy3IfmfqS0YOKuQ2NSekBN5aHHKCoPuQARQUiCyipEGA2VwiwmysENJsrRBZRViHyiKIKkUcUVYhsOMsqRBZR9nmXI9Z83rjkNuL75/npZu2xn/40hi76ch5hHnEeaR6Ve7TrBrRvYCphgrHBNGFN1mEqHcMntQT2I/uJrWKreZ1pvg2ddcwD5oFkC2yR15kHKujAN7WuYoLjoZ/7ttYFEZpgsQ5+lDx3PHT//ojsJ/Yrtpr9hueW9zfBT3XwE/MI2I88p7CfPM/fwG879e1h6Hy4/YXcxmOMvpte/13iSmzcL9P52J1uU+dv6qV7d+MHUAXN58Pf5n8=",
  "file_map": {
    "17": {
      "source": "use crate::field::field_less_than;\nuse crate::runtime::is_unconstrained;\n\n// The low and high decomposition of the field modulus\nglobal PLO: Field = 53438638232309528389504892708671455233;\nglobal PHI: Field = 64323764613183177041862057485226039389;\n\npub(crate) global TWO_POW_128: Field = 0x100000000000000000000000000000000;\n\n// Decomposes a single field into two 16 byte fields.\nfn compute_decomposition(x: Field) -> (Field, Field) {\n    // Here's we're taking advantage of truncating 128 bit limbs from the input field\n    // and then subtracting them from the input such the field division is equivalent to integer division.\n    let low = (x as u128) as Field;\n    let high = (x - low) / TWO_POW_128;\n\n    (low, high)\n}\n\npub(crate) unconstrained fn decompose_hint(x: Field) -> (Field, Field) {\n    compute_decomposition(x)\n}\n\nunconstrained fn lte_hint(x: Field, y: Field) -> bool {\n    if x == y {\n        true\n    } else {\n        field_less_than(x, y)\n    }\n}\n\n// Assert that (alo > blo && ahi >= bhi) || (alo <= blo && ahi > bhi)\nfn assert_gt_limbs(a: (Field, Field), b: (Field, Field)) {\n    let (alo, ahi) = a;\n    let (blo, bhi) = b;\n    // Safety: borrow is enforced to be boolean due to its type.\n    // if borrow is 0, it asserts that (alo > blo && ahi >= bhi)\n    // if borrow is 1, it asserts that (alo <= blo && ahi > bhi)\n    unsafe {\n        let borrow = lte_hint(alo, blo);\n\n        let rlo = alo - blo - 1 + (borrow as Field) * TWO_POW_128;\n        let rhi = ahi - bhi - (borrow as Field);\n\n        rlo.assert_max_bit_size::<128>();\n        rhi.assert_max_bit_size::<128>();\n    }\n}\n\n/// Decompose a single field into two 16 byte fields.\npub fn decompose(x: Field) -> (Field, Field) {\n    if is_unconstrained() {\n        compute_decomposition(x)\n    } else {\n        // Safety: decomposition is properly checked below\n        unsafe {\n            // Take hints of the decomposition\n            let (xlo, xhi) = decompose_hint(x);\n\n            // Range check the limbs\n            xlo.assert_max_bit_size::<128>();\n            xhi.assert_max_bit_size::<128>();\n\n            // Check that the decomposition is correct\n            assert_eq(x, xlo + TWO_POW_128 * xhi);\n\n            // Assert that the decomposition of P is greater than the decomposition of x\n            assert_gt_limbs((PLO, PHI), (xlo, xhi));\n            (xlo, xhi)\n        }\n    }\n}\n\npub fn assert_gt(a: Field, b: Field) {\n    if is_unconstrained() {\n        assert(\n            // Safety: already unconstrained\n            unsafe { field_less_than(b, a) },\n        );\n    } else {\n        // Decompose a and b\n        let a_limbs = decompose(a);\n        let b_limbs = decompose(b);\n\n        // Assert that a_limbs is greater than b_limbs\n        assert_gt_limbs(a_limbs, b_limbs)\n    }\n}\n\npub fn assert_lt(a: Field, b: Field) {\n    assert_gt(b, a);\n}\n\npub fn gt(a: Field, b: Field) -> bool {\n    if is_unconstrained() {\n        // Safety: unsafe in unconstrained\n        unsafe {\n            field_less_than(b, a)\n        }\n    } else if a == b {\n        false\n    } else {\n        // Safety: Take a hint of the comparison and verify it\n        unsafe {\n            if field_less_than(a, b) {\n                assert_gt(b, a);\n                false\n            } else {\n                assert_gt(a, b);\n                true\n            }\n        }\n    }\n}\n\npub fn lt(a: Field, b: Field) -> bool {\n    gt(b, a)\n}\n\nmod tests {\n    // TODO: Allow imports from \"super\"\n    use crate::field::bn254::{assert_gt, decompose, gt, lte_hint, PHI, PLO, TWO_POW_128};\n\n    #[test]\n    fn check_decompose() {\n        assert_eq(decompose(TWO_POW_128), (0, 1));\n        assert_eq(decompose(TWO_POW_128 + 0x1234567890), (0x1234567890, 1));\n        assert_eq(decompose(0x1234567890), (0x1234567890, 0));\n    }\n\n    #[test]\n    unconstrained fn check_decompose_unconstrained() {\n        assert_eq(decompose(TWO_POW_128), (0, 1));\n        assert_eq(decompose(TWO_POW_128 + 0x1234567890), (0x1234567890, 1));\n        assert_eq(decompose(0x1234567890), (0x1234567890, 0));\n    }\n\n    #[test]\n    unconstrained fn check_lte_hint() {\n        assert(lte_hint(0, 1));\n        assert(lte_hint(0, 0x100));\n        assert(lte_hint(0x100, TWO_POW_128 - 1));\n        assert(!lte_hint(0 - 1, 0));\n\n        assert(lte_hint(0, 0));\n        assert(lte_hint(0x100, 0x100));\n        assert(lte_hint(0 - 1, 0 - 1));\n    }\n\n    #[test]\n    fn check_assert_gt() {\n        assert_gt(1, 0);\n        assert_gt(0x100, 0);\n        assert_gt((0 - 1), (0 - 2));\n        assert_gt(TWO_POW_128, 0);\n        assert_gt(0 - 1, 0);\n    }\n\n    #[test]\n    unconstrained fn check_assert_gt_unconstrained() {\n        assert_gt(1, 0);\n        assert_gt(0x100, 0);\n        assert_gt((0 - 1), (0 - 2));\n        assert_gt(TWO_POW_128, 0);\n        assert_gt(0 - 1, 0);\n    }\n\n    #[test]\n    fn check_gt() {\n        assert(gt(1, 0));\n        assert(gt(0x100, 0));\n        assert(gt((0 - 1), (0 - 2)));\n        assert(gt(TWO_POW_128, 0));\n        assert(!gt(0, 0));\n        assert(!gt(0, 0x100));\n        assert(gt(0 - 1, 0 - 2));\n        assert(!gt(0 - 2, 0 - 1));\n    }\n\n    #[test]\n    unconstrained fn check_gt_unconstrained() {\n        assert(gt(1, 0));\n        assert(gt(0x100, 0));\n        assert(gt((0 - 1), (0 - 2)));\n        assert(gt(TWO_POW_128, 0));\n        assert(!gt(0, 0));\n        assert(!gt(0, 0x100));\n        assert(gt(0 - 1, 0 - 2));\n        assert(!gt(0 - 2, 0 - 1));\n    }\n\n    #[test]\n    fn check_plo_phi() {\n        assert_eq(PLO + PHI * TWO_POW_128, 0);\n        let p_bytes = crate::field::modulus_le_bytes();\n        let mut p_low: Field = 0;\n        let mut p_high: Field = 0;\n\n        let mut offset = 1;\n        for i in 0..16 {\n            p_low += (p_bytes[i] as Field) * offset;\n            p_high += (p_bytes[i + 16] as Field) * offset;\n            offset *= 256;\n        }\n        assert_eq(p_low, PLO);\n        assert_eq(p_high, PHI);\n    }\n}\n",
      "path": "std/field/bn254.nr"
    },
    "18": {
      "source": "pub mod bn254;\nuse crate::{runtime::is_unconstrained, static_assert};\nuse bn254::lt as bn254_lt;\n\nimpl Field {\n    /// Asserts that `self` can be represented in `bit_size` bits.\n    ///\n    /// # Failures\n    /// Causes a constraint failure for `Field` values exceeding `2^{bit_size}`.\n    // docs:start:assert_max_bit_size\n    pub fn assert_max_bit_size<let BIT_SIZE: u32>(self) {\n        // docs:end:assert_max_bit_size\n        static_assert(\n            BIT_SIZE < modulus_num_bits() as u32,\n            \"BIT_SIZE must be less than modulus_num_bits\",\n        );\n        __assert_max_bit_size(self, BIT_SIZE);\n    }\n\n    /// Decomposes `self` into its little endian bit decomposition as a `[u1; N]` array.\n    /// This slice will be zero padded should not all bits be necessary to represent `self`.\n    ///\n    /// # Failures\n    /// Causes a constraint failure for `Field` values exceeding `2^N` as the resulting slice will not\n    /// be able to represent the original `Field`.\n    ///\n    /// # Safety\n    /// The bit decomposition returned is canonical and is guaranteed to not overflow the modulus.\n    // docs:start:to_le_bits\n    pub fn to_le_bits<let N: u32>(self: Self) -> [u1; N] {\n        // docs:end:to_le_bits\n        let bits = __to_le_bits(self);\n\n        if !is_unconstrained() {\n            // Ensure that the byte decomposition does not overflow the modulus\n            let p = modulus_le_bits();\n            assert(bits.len() <= p.len());\n            let mut ok = bits.len() != p.len();\n            for i in 0..N {\n                if !ok {\n                    if (bits[N - 1 - i] != p[N - 1 - i]) {\n                        assert(p[N - 1 - i] == 1);\n                        ok = true;\n                    }\n                }\n            }\n            assert(ok);\n        }\n        bits\n    }\n\n    /// Decomposes `self` into its big endian bit decomposition as a `[u1; N]` array.\n    /// This array will be zero padded should not all bits be necessary to represent `self`.\n    ///\n    /// # Failures\n    /// Causes a constraint failure for `Field` values exceeding `2^N` as the resulting slice will not\n    /// be able to represent the original `Field`.\n    ///\n    /// # Safety\n    /// The bit decomposition returned is canonical and is guaranteed to not overflow the modulus.\n    // docs:start:to_be_bits\n    pub fn to_be_bits<let N: u32>(self: Self) -> [u1; N] {\n        // docs:end:to_be_bits\n        let bits = __to_be_bits(self);\n\n        if !is_unconstrained() {\n            // Ensure that the decomposition does not overflow the modulus\n            let p = modulus_be_bits();\n            assert(bits.len() <= p.len());\n            let mut ok = bits.len() != p.len();\n            for i in 0..N {\n                if !ok {\n                    if (bits[i] != p[i]) {\n                        assert(p[i] == 1);\n                        ok = true;\n                    }\n                }\n            }\n            assert(ok);\n        }\n        bits\n    }\n\n    /// Decomposes `self` into its little endian byte decomposition as a `[u8;N]` array\n    /// This array will be zero padded should not all bytes be necessary to represent `self`.\n    ///\n    /// # Failures\n    ///  The length N of the array must be big enough to contain all the bytes of the 'self',\n    ///  and no more than the number of bytes required to represent the field modulus\n    ///\n    /// # Safety\n    /// The result is ensured to be the canonical decomposition of the field element\n    // docs:start:to_le_bytes\n    pub fn to_le_bytes<let N: u32>(self: Self) -> [u8; N] {\n        // docs:end:to_le_bytes\n        static_assert(\n            N <= modulus_le_bytes().len(),\n            \"N must be less than or equal to modulus_le_bytes().len()\",\n        );\n        // Compute the byte decomposition\n        let bytes = self.to_le_radix(256);\n\n        if !is_unconstrained() {\n            // Ensure that the byte decomposition does not overflow the modulus\n            let p = modulus_le_bytes();\n            assert(bytes.len() <= p.len());\n            let mut ok = bytes.len() != p.len();\n            for i in 0..N {\n                if !ok {\n                    if (bytes[N - 1 - i] != p[N - 1 - i]) {\n                        assert(bytes[N - 1 - i] < p[N - 1 - i]);\n                        ok = true;\n                    }\n                }\n            }\n            assert(ok);\n        }\n        bytes\n    }\n\n    /// Decomposes `self` into its big endian byte decomposition as a `[u8;N]` array of length required to represent the field modulus\n    /// This array will be zero padded should not all bytes be necessary to represent `self`.\n    ///\n    /// # Failures\n    ///  The length N of the array must be big enough to contain all the bytes of the 'self',\n    ///  and no more than the number of bytes required to represent the field modulus\n    ///\n    /// # Safety\n    /// The result is ensured to be the canonical decomposition of the field element\n    // docs:start:to_be_bytes\n    pub fn to_be_bytes<let N: u32>(self: Self) -> [u8; N] {\n        // docs:end:to_be_bytes\n        static_assert(\n            N <= modulus_le_bytes().len(),\n            \"N must be less than or equal to modulus_le_bytes().len()\",\n        );\n        // Compute the byte decomposition\n        let bytes = self.to_be_radix(256);\n\n        if !is_unconstrained() {\n            // Ensure that the byte decomposition does not overflow the modulus\n            let p = modulus_be_bytes();\n            assert(bytes.len() <= p.len());\n            let mut ok = bytes.len() != p.len();\n            for i in 0..N {\n                if !ok {\n                    if (bytes[i] != p[i]) {\n                        assert(bytes[i] < p[i]);\n                        ok = true;\n                    }\n                }\n            }\n            assert(ok);\n        }\n        bytes\n    }\n\n    fn to_le_radix<let N: u32>(self: Self, radix: u32) -> [u8; N] {\n        // Brillig does not need an immediate radix\n        if !crate::runtime::is_unconstrained() {\n            static_assert(1 < radix, \"radix must be greater than 1\");\n            static_assert(radix <= 256, \"radix must be less than or equal to 256\");\n            static_assert(radix & (radix - 1) == 0, \"radix must be a power of 2\");\n        }\n        __to_le_radix(self, radix)\n    }\n\n    fn to_be_radix<let N: u32>(self: Self, radix: u32) -> [u8; N] {\n        // Brillig does not need an immediate radix\n        if !crate::runtime::is_unconstrained() {\n            static_assert(1 < radix, \"radix must be greater than 1\");\n            static_assert(radix <= 256, \"radix must be less than or equal to 256\");\n            static_assert(radix & (radix - 1) == 0, \"radix must be a power of 2\");\n        }\n        __to_be_radix(self, radix)\n    }\n\n    // Returns self to the power of the given exponent value.\n    // Caution: we assume the exponent fits into 32 bits\n    // using a bigger bit size impacts negatively the performance and should be done only if the exponent does not fit in 32 bits\n    pub fn pow_32(self, exponent: Field) -> Field {\n        let mut r: Field = 1;\n        let b: [u1; 32] = exponent.to_le_bits();\n\n        for i in 1..33 {\n            r *= r;\n            r = (b[32 - i] as Field) * (r * self) + (1 - b[32 - i] as Field) * r;\n        }\n        r\n    }\n\n    // Parity of (prime) Field element, i.e. sgn0(x mod p) = 0 if x `elem` {0, ..., p-1} is even, otherwise sgn0(x mod p) = 1.\n    pub fn sgn0(self) -> u1 {\n        self as u1\n    }\n\n    pub fn lt(self, another: Field) -> bool {\n        if crate::compat::is_bn254() {\n            bn254_lt(self, another)\n        } else {\n            lt_fallback(self, another)\n        }\n    }\n\n    /// Convert a little endian byte array to a field element.\n    /// If the provided byte array overflows the field modulus then the Field will silently wrap around.\n    pub fn from_le_bytes<let N: u32>(bytes: [u8; N]) -> Field {\n        static_assert(\n            N <= modulus_le_bytes().len(),\n            \"N must be less than or equal to modulus_le_bytes().len()\",\n        );\n        let mut v = 1;\n        let mut result = 0;\n\n        for i in 0..N {\n            result += (bytes[i] as Field) * v;\n            v = v * 256;\n        }\n        result\n    }\n\n    /// Convert a big endian byte array to a field element.\n    /// If the provided byte array overflows the field modulus then the Field will silently wrap around.\n    pub fn from_be_bytes<let N: u32>(bytes: [u8; N]) -> Field {\n        let mut v = 1;\n        let mut result = 0;\n\n        for i in 0..N {\n            result += (bytes[N - 1 - i] as Field) * v;\n            v = v * 256;\n        }\n        result\n    }\n}\n\n#[builtin(apply_range_constraint)]\nfn __assert_max_bit_size(value: Field, bit_size: u32) {}\n\n// `_radix` must be less than 256\n#[builtin(to_le_radix)]\nfn __to_le_radix<let N: u32>(value: Field, radix: u32) -> [u8; N] {}\n\n// `_radix` must be less than 256\n#[builtin(to_be_radix)]\nfn __to_be_radix<let N: u32>(value: Field, radix: u32) -> [u8; N] {}\n\n/// Decomposes `self` into its little endian bit decomposition as a `[u1; N]` array.\n/// This slice will be zero padded should not all bits be necessary to represent `self`.\n///\n/// # Failures\n/// Causes a constraint failure for `Field` values exceeding `2^N` as the resulting slice will not\n/// be able to represent the original `Field`.\n///\n/// # Safety\n/// Values of `N` equal to or greater than the number of bits necessary to represent the `Field` modulus\n/// (e.g. 254 for the BN254 field) allow for multiple bit decompositions. This is due to how the `Field` will\n/// wrap around due to overflow when verifying the decomposition.\n#[builtin(to_le_bits)]\nfn __to_le_bits<let N: u32>(value: Field) -> [u1; N] {}\n\n/// Decomposes `self` into its big endian bit decomposition as a `[u1; N]` array.\n/// This array will be zero padded should not all bits be necessary to represent `self`.\n///\n/// # Failures\n/// Causes a constraint failure for `Field` values exceeding `2^N` as the resulting slice will not\n/// be able to represent the original `Field`.\n///\n/// # Safety\n/// Values of `N` equal to or greater than the number of bits necessary to represent the `Field` modulus\n/// (e.g. 254 for the BN254 field) allow for multiple bit decompositions. This is due to how the `Field` will\n/// wrap around due to overflow when verifying the decomposition.\n#[builtin(to_be_bits)]\nfn __to_be_bits<let N: u32>(value: Field) -> [u1; N] {}\n\n#[builtin(modulus_num_bits)]\npub comptime fn modulus_num_bits() -> u64 {}\n\n#[builtin(modulus_be_bits)]\npub comptime fn modulus_be_bits() -> [u1] {}\n\n#[builtin(modulus_le_bits)]\npub comptime fn modulus_le_bits() -> [u1] {}\n\n#[builtin(modulus_be_bytes)]\npub comptime fn modulus_be_bytes() -> [u8] {}\n\n#[builtin(modulus_le_bytes)]\npub comptime fn modulus_le_bytes() -> [u8] {}\n\n/// An unconstrained only built in to efficiently compare fields.\n#[builtin(field_less_than)]\nunconstrained fn __field_less_than(x: Field, y: Field) -> bool {}\n\npub(crate) unconstrained fn field_less_than(x: Field, y: Field) -> bool {\n    __field_less_than(x, y)\n}\n\n// Convert a 32 byte array to a field element by modding\npub fn bytes32_to_field(bytes32: [u8; 32]) -> Field {\n    // Convert it to a field element\n    let mut v = 1;\n    let mut high = 0 as Field;\n    let mut low = 0 as Field;\n\n    for i in 0..16 {\n        high = high + (bytes32[15 - i] as Field) * v;\n        low = low + (bytes32[16 + 15 - i] as Field) * v;\n        v = v * 256;\n    }\n    // Abuse that a % p + b % p = (a + b) % p and that low < p\n    low + high * v\n}\n\nfn lt_fallback(x: Field, y: Field) -> bool {\n    if is_unconstrained() {\n        // Safety: unconstrained context\n        unsafe {\n            field_less_than(x, y)\n        }\n    } else {\n        let x_bytes: [u8; 32] = x.to_le_bytes();\n        let y_bytes: [u8; 32] = y.to_le_bytes();\n        let mut x_is_lt = false;\n        let mut done = false;\n        for i in 0..32 {\n            if (!done) {\n                let x_byte = x_bytes[32 - 1 - i] as u8;\n                let y_byte = y_bytes[32 - 1 - i] as u8;\n                let bytes_match = x_byte == y_byte;\n                if !bytes_match {\n                    x_is_lt = x_byte < y_byte;\n                    done = true;\n                }\n            }\n        }\n        x_is_lt\n    }\n}\n\nmod tests {\n    use crate::{panic::panic, runtime};\n    use super::field_less_than;\n\n    #[test]\n    // docs:start:to_be_bits_example\n    fn test_to_be_bits() {\n        let field = 2;\n        let bits: [u1; 8] = field.to_be_bits();\n        assert_eq(bits, [0, 0, 0, 0, 0, 0, 1, 0]);\n    }\n    // docs:end:to_be_bits_example\n\n    #[test]\n    // docs:start:to_le_bits_example\n    fn test_to_le_bits() {\n        let field = 2;\n        let bits: [u1; 8] = field.to_le_bits();\n        assert_eq(bits, [0, 1, 0, 0, 0, 0, 0, 0]);\n    }\n    // docs:end:to_le_bits_example\n\n    #[test]\n    // docs:start:to_be_bytes_example\n    fn test_to_be_bytes() {\n        let field = 2;\n        let bytes: [u8; 8] = field.to_be_bytes();\n        assert_eq(bytes, [0, 0, 0, 0, 0, 0, 0, 2]);\n        assert_eq(Field::from_be_bytes::<8>(bytes), field);\n    }\n    // docs:end:to_be_bytes_example\n\n    #[test]\n    // docs:start:to_le_bytes_example\n    fn test_to_le_bytes() {\n        let field = 2;\n        let bytes: [u8; 8] = field.to_le_bytes();\n        assert_eq(bytes, [2, 0, 0, 0, 0, 0, 0, 0]);\n        assert_eq(Field::from_le_bytes::<8>(bytes), field);\n    }\n    // docs:end:to_le_bytes_example\n\n    #[test]\n    // docs:start:to_be_radix_example\n    fn test_to_be_radix() {\n        // 259, in base 256, big endian, is [1, 3].\n        // i.e. 3 * 256^0 + 1 * 256^1\n        let field = 259;\n\n        // The radix (in this example, 256) must be a power of 2.\n        // The length of the returned byte array can be specified to be\n        // >= the amount of space needed.\n        let bytes: [u8; 8] = field.to_be_radix(256);\n        assert_eq(bytes, [0, 0, 0, 0, 0, 0, 1, 3]);\n        assert_eq(Field::from_be_bytes::<8>(bytes), field);\n    }\n    // docs:end:to_be_radix_example\n\n    #[test]\n    // docs:start:to_le_radix_example\n    fn test_to_le_radix() {\n        // 259, in base 256, little endian, is [3, 1].\n        // i.e. 3 * 256^0 + 1 * 256^1\n        let field = 259;\n\n        // The radix (in this example, 256) must be a power of 2.\n        // The length of the returned byte array can be specified to be\n        // >= the amount of space needed.\n        let bytes: [u8; 8] = field.to_le_radix(256);\n        assert_eq(bytes, [3, 1, 0, 0, 0, 0, 0, 0]);\n        assert_eq(Field::from_le_bytes::<8>(bytes), field);\n    }\n    // docs:end:to_le_radix_example\n\n    #[test(should_fail_with = \"radix must be greater than 1\")]\n    fn test_to_le_radix_1() {\n        // this test should only fail in constrained mode\n        if !runtime::is_unconstrained() {\n            let field = 2;\n            let _: [u8; 8] = field.to_le_radix(1);\n        } else {\n            panic(f\"radix must be greater than 1\");\n        }\n    }\n\n    // TODO: Update this test to account for the Brillig restriction that the radix must be greater than 2\n    //#[test]\n    //fn test_to_le_radix_brillig_1() {\n    //    // this test should only fail in constrained mode\n    //    if runtime::is_unconstrained() {\n    //        let field = 1;\n    //        let out: [u8; 8] = field.to_le_radix(1);\n    //        crate::println(out);\n    //        let expected = [0; 8];\n    //        assert(out == expected, \"unexpected result\");\n    //    }\n    //}\n\n    #[test(should_fail_with = \"radix must be a power of 2\")]\n    fn test_to_le_radix_3() {\n        // this test should only fail in constrained mode\n        if !runtime::is_unconstrained() {\n            let field = 2;\n            let _: [u8; 8] = field.to_le_radix(3);\n        } else {\n            panic(f\"radix must be a power of 2\");\n        }\n    }\n\n    #[test]\n    fn test_to_le_radix_brillig_3() {\n        // this test should only fail in constrained mode\n        if runtime::is_unconstrained() {\n            let field = 1;\n            let out: [u8; 8] = field.to_le_radix(3);\n            let mut expected = [0; 8];\n            expected[0] = 1;\n            assert(out == expected, \"unexpected result\");\n        }\n    }\n\n    #[test(should_fail_with = \"radix must be less than or equal to 256\")]\n    fn test_to_le_radix_512() {\n        // this test should only fail in constrained mode\n        if !runtime::is_unconstrained() {\n            let field = 2;\n            let _: [u8; 8] = field.to_le_radix(512);\n        } else {\n            panic(f\"radix must be less than or equal to 256\")\n        }\n    }\n\n    // TODO: Update this test to account for the Brillig restriction that the radix must be less than 512\n    //#[test]\n    //fn test_to_le_radix_brillig_512() {\n    //    // this test should only fail in constrained mode\n    //    if runtime::is_unconstrained() {\n    //        let field = 1;\n    //        let out: [u8; 8] = field.to_le_radix(512);\n    //        let mut expected = [0; 8];\n    //        expected[0] = 1;\n    //        assert(out == expected, \"unexpected result\");\n    //    }\n    //}\n\n    #[test]\n    unconstrained fn test_field_less_than() {\n        assert(field_less_than(0, 1));\n        assert(field_less_than(0, 0x100));\n        assert(field_less_than(0x100, 0 - 1));\n        assert(!field_less_than(0 - 1, 0));\n    }\n}\n",
      "path": "std/field/mod.nr"
    },
    "19": {
      "source": "// Exposed only for usage in `std::meta`\npub(crate) mod poseidon2;\n\nuse crate::default::Default;\nuse crate::embedded_curve_ops::{\n    EmbeddedCurvePoint, EmbeddedCurveScalar, multi_scalar_mul, multi_scalar_mul_array_return,\n};\nuse crate::meta::derive_via;\n\n#[foreign(sha256_compression)]\n// docs:start:sha256_compression\npub fn sha256_compression(input: [u32; 16], state: [u32; 8]) -> [u32; 8] {}\n// docs:end:sha256_compression\n\n#[foreign(keccakf1600)]\n// docs:start:keccakf1600\npub fn keccakf1600(input: [u64; 25]) -> [u64; 25] {}\n// docs:end:keccakf1600\n\npub mod keccak {\n    #[deprecated(\"This function has been moved to std::hash::keccakf1600\")]\n    pub fn keccakf1600(input: [u64; 25]) -> [u64; 25] {\n        super::keccakf1600(input)\n    }\n}\n\n#[foreign(blake2s)]\n// docs:start:blake2s\npub fn blake2s<let N: u32>(input: [u8; N]) -> [u8; 32]\n// docs:end:blake2s\n{}\n\n#[foreign(blake3)]\n// docs:start:blake3\npub fn blake3<let N: u32>(input: [u8; N]) -> [u8; 32]\n// docs:end:blake3\n{}\n\n// docs:start:pedersen_commitment\npub fn pedersen_commitment<let N: u32>(input: [Field; N]) -> EmbeddedCurvePoint {\n    // docs:end:pedersen_commitment\n    pedersen_commitment_with_separator(input, 0)\n}\n\n#[inline_always]\npub fn pedersen_commitment_with_separator<let N: u32>(\n    input: [Field; N],\n    separator: u32,\n) -> EmbeddedCurvePoint {\n    let mut points = [EmbeddedCurveScalar { lo: 0, hi: 0 }; N];\n    for i in 0..N {\n        // we use the unsafe version because the multi_scalar_mul will constrain the scalars.\n        points[i] = from_field_unsafe(input[i]);\n    }\n    let generators = derive_generators(\"DEFAULT_DOMAIN_SEPARATOR\".as_bytes(), separator);\n    multi_scalar_mul(generators, points)\n}\n\n// docs:start:pedersen_hash\npub fn pedersen_hash<let N: u32>(input: [Field; N]) -> Field\n// docs:end:pedersen_hash\n{\n    pedersen_hash_with_separator(input, 0)\n}\n\n#[no_predicates]\npub fn pedersen_hash_with_separator<let N: u32>(input: [Field; N], separator: u32) -> Field {\n    let mut scalars: [EmbeddedCurveScalar; N + 1] = [EmbeddedCurveScalar { lo: 0, hi: 0 }; N + 1];\n    let mut generators: [EmbeddedCurvePoint; N + 1] =\n        [EmbeddedCurvePoint::point_at_infinity(); N + 1];\n    let domain_generators: [EmbeddedCurvePoint; N] =\n        derive_generators(\"DEFAULT_DOMAIN_SEPARATOR\".as_bytes(), separator);\n\n    for i in 0..N {\n        scalars[i] = from_field_unsafe(input[i]);\n        generators[i] = domain_generators[i];\n    }\n    scalars[N] = EmbeddedCurveScalar { lo: N as Field, hi: 0 as Field };\n\n    let length_generator: [EmbeddedCurvePoint; 1] =\n        derive_generators(\"pedersen_hash_length\".as_bytes(), 0);\n    generators[N] = length_generator[0];\n    multi_scalar_mul_array_return(generators, scalars)[0].x\n}\n\n#[field(bn254)]\n#[inline_always]\npub fn derive_generators<let N: u32, let M: u32>(\n    domain_separator_bytes: [u8; M],\n    starting_index: u32,\n) -> [EmbeddedCurvePoint; N] {\n    crate::assert_constant(domain_separator_bytes);\n    // TODO(https://github.com/noir-lang/noir/issues/5672): Add back assert_constant on starting_index\n    __derive_generators(domain_separator_bytes, starting_index)\n}\n\n#[builtin(derive_pedersen_generators)]\n#[field(bn254)]\nfn __derive_generators<let N: u32, let M: u32>(\n    domain_separator_bytes: [u8; M],\n    starting_index: u32,\n) -> [EmbeddedCurvePoint; N] {}\n\n#[field(bn254)]\n// Same as from_field but:\n// does not assert the limbs are 128 bits\n// does not assert the decomposition does not overflow the EmbeddedCurveScalar\nfn from_field_unsafe(scalar: Field) -> EmbeddedCurveScalar {\n    // Safety: xlo and xhi decomposition is checked below\n    let (xlo, xhi) = unsafe { crate::field::bn254::decompose_hint(scalar) };\n    // Check that the decomposition is correct\n    assert_eq(scalar, xlo + crate::field::bn254::TWO_POW_128 * xhi);\n    EmbeddedCurveScalar { lo: xlo, hi: xhi }\n}\n\npub fn hash_to_field(inputs: [Field]) -> Field {\n    let mut sum = 0;\n\n    for input in inputs {\n        let input_bytes: [u8; 32] = input.to_le_bytes();\n        sum += crate::field::bytes32_to_field(blake2s(input_bytes));\n    }\n\n    sum\n}\n\n#[foreign(poseidon2_permutation)]\npub fn poseidon2_permutation<let N: u32>(_input: [Field; N], _state_length: u32) -> [Field; N] {}\n\n// Generic hashing support.\n// Partially ported and impacted by rust.\n\n// Hash trait shall be implemented per type.\n#[derive_via(derive_hash)]\npub trait Hash {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher;\n}\n\n// docs:start:derive_hash\ncomptime fn derive_hash(s: TypeDefinition) -> Quoted {\n    let name = quote { Hash };\n    let signature = quote { fn hash<H>(_self: Self, _state: &mut H) where H: std::hash::Hasher };\n    let for_each_field = |name| quote { _self.$name.hash(_state); };\n    crate::meta::make_trait_impl(\n        s,\n        name,\n        signature,\n        for_each_field,\n        quote {},\n        |fields| fields,\n    )\n}\n// docs:end:derive_hash\n\n// Hasher trait shall be implemented by algorithms to provide hash-agnostic means.\n// TODO: consider making the types generic here ([u8], [Field], etc.)\npub trait Hasher {\n    fn finish(self) -> Field;\n\n    fn write(&mut self, input: Field);\n}\n\n// BuildHasher is a factory trait, responsible for production of specific Hasher.\npub trait BuildHasher<H>\nwhere\n    H: Hasher,\n{\n    fn build_hasher(self) -> H;\n}\n\npub struct BuildHasherDefault<H>;\n\nimpl<H> BuildHasher<H> for BuildHasherDefault<H>\nwhere\n    H: Hasher + Default,\n{\n    fn build_hasher(_self: Self) -> H {\n        H::default()\n    }\n}\n\nimpl<H> Default for BuildHasherDefault<H>\nwhere\n    H: Hasher + Default,\n{\n    fn default() -> Self {\n        BuildHasherDefault {}\n    }\n}\n\nimpl Hash for Field {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self);\n    }\n}\n\nimpl Hash for u1 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u8 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u16 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u32 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u64 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u128 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for i8 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for i16 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for i32 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for i64 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for bool {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for () {\n    fn hash<H>(_self: Self, _state: &mut H)\n    where\n        H: Hasher,\n    {}\n}\n\nimpl<T, let N: u32> Hash for [T; N]\nwhere\n    T: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        for elem in self {\n            elem.hash(state);\n        }\n    }\n}\n\nimpl<T> Hash for [T]\nwhere\n    T: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.len().hash(state);\n        for elem in self {\n            elem.hash(state);\n        }\n    }\n}\n\nimpl<A, B> Hash for (A, B)\nwhere\n    A: Hash,\n    B: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.0.hash(state);\n        self.1.hash(state);\n    }\n}\n\nimpl<A, B, C> Hash for (A, B, C)\nwhere\n    A: Hash,\n    B: Hash,\n    C: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.0.hash(state);\n        self.1.hash(state);\n        self.2.hash(state);\n    }\n}\n\nimpl<A, B, C, D> Hash for (A, B, C, D)\nwhere\n    A: Hash,\n    B: Hash,\n    C: Hash,\n    D: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.0.hash(state);\n        self.1.hash(state);\n        self.2.hash(state);\n        self.3.hash(state);\n    }\n}\n\nimpl<A, B, C, D, E> Hash for (A, B, C, D, E)\nwhere\n    A: Hash,\n    B: Hash,\n    C: Hash,\n    D: Hash,\n    E: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.0.hash(state);\n        self.1.hash(state);\n        self.2.hash(state);\n        self.3.hash(state);\n        self.4.hash(state);\n    }\n}\n\n// Some test vectors for Pedersen hash and Pedersen Commitment.\n// They have been generated using the same functions so the tests are for now useless\n// but they will be useful when we switch to Noir implementation.\n#[test]\nfn assert_pedersen() {\n    assert_eq(\n        pedersen_hash_with_separator([1], 1),\n        0x1b3f4b1a83092a13d8d1a59f7acb62aba15e7002f4440f2275edb99ebbc2305f,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1], 1),\n        EmbeddedCurvePoint {\n            x: 0x054aa86a73cb8a34525e5bbed6e43ba1198e860f5f3950268f71df4591bde402,\n            y: 0x209dcfbf2cfb57f9f6046f44d71ac6faf87254afc7407c04eb621a6287cac126,\n            is_infinite: false,\n        },\n    );\n\n    assert_eq(\n        pedersen_hash_with_separator([1, 2], 2),\n        0x26691c129448e9ace0c66d11f0a16d9014a9e8498ee78f4d69f0083168188255,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2], 2),\n        EmbeddedCurvePoint {\n            x: 0x2e2b3b191e49541fe468ec6877721d445dcaffe41728df0a0eafeb15e87b0753,\n            y: 0x2ff4482400ad3a6228be17a2af33e2bcdf41be04795f9782bd96efe7e24f8778,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3], 3),\n        0x0bc694b7a1f8d10d2d8987d07433f26bd616a2d351bc79a3c540d85b6206dbe4,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3], 3),\n        EmbeddedCurvePoint {\n            x: 0x1fee4e8cf8d2f527caa2684236b07c4b1bad7342c01b0f75e9a877a71827dc85,\n            y: 0x2f9fedb9a090697ab69bf04c8bc15f7385b3e4b68c849c1536e5ae15ff138fd1,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4], 4),\n        0xdae10fb32a8408521803905981a2b300d6a35e40e798743e9322b223a5eddc,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4], 4),\n        EmbeddedCurvePoint {\n            x: 0x07ae3e202811e1fca39c2d81eabe6f79183978e6f12be0d3b8eda095b79bdbc9,\n            y: 0x0afc6f892593db6fbba60f2da558517e279e0ae04f95758587760ba193145014,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5], 5),\n        0xfc375b062c4f4f0150f7100dfb8d9b72a6d28582dd9512390b0497cdad9c22,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5], 5),\n        EmbeddedCurvePoint {\n            x: 0x1754b12bd475a6984a1094b5109eeca9838f4f81ac89c5f0a41dbce53189bb29,\n            y: 0x2da030e3cfcdc7ddad80eaf2599df6692cae0717d4e9f7bfbee8d073d5d278f7,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6], 6),\n        0x1696ed13dc2730062a98ac9d8f9de0661bb98829c7582f699d0273b18c86a572,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6], 6),\n        EmbeddedCurvePoint {\n            x: 0x190f6c0e97ad83e1e28da22a98aae156da083c5a4100e929b77e750d3106a697,\n            y: 0x1f4b60f34ef91221a0b49756fa0705da93311a61af73d37a0c458877706616fb,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7], 7),\n        0x128c0ff144fc66b6cb60eeac8a38e23da52992fc427b92397a7dffd71c45ede3,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7], 7),\n        EmbeddedCurvePoint {\n            x: 0x015441e9d29491b06563fac16fc76abf7a9534c715421d0de85d20dbe2965939,\n            y: 0x1d2575b0276f4e9087e6e07c2cb75aa1baafad127af4be5918ef8a2ef2fea8fc,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7, 8], 8),\n        0x2f960e117482044dfc99d12fece2ef6862fba9242be4846c7c9a3e854325a55c,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7, 8], 8),\n        EmbeddedCurvePoint {\n            x: 0x1657737676968887fceb6dd516382ea13b3a2c557f509811cd86d5d1199bc443,\n            y: 0x1f39f0cb569040105fa1e2f156521e8b8e08261e635a2b210bdc94e8d6d65f77,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9], 9),\n        0x0c96db0790602dcb166cc4699e2d306c479a76926b81c2cb2aaa92d249ec7be7,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9], 9),\n        EmbeddedCurvePoint {\n            x: 0x0a3ceae42d14914a432aa60ec7fded4af7dad7dd4acdbf2908452675ec67e06d,\n            y: 0xfc19761eaaf621ad4aec9a8b2e84a4eceffdba78f60f8b9391b0bd9345a2f2,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 10),\n        0x2cd37505871bc460a62ea1e63c7fe51149df5d0801302cf1cbc48beb8dff7e94,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 10),\n        EmbeddedCurvePoint {\n            x: 0x2fb3f8b3d41ddde007c8c3c62550f9a9380ee546fcc639ffbb3fd30c8d8de30c,\n            y: 0x300783be23c446b11a4c0fabf6c91af148937cea15fcf5fb054abf7f752ee245,\n            is_infinite: false,\n        },\n    );\n}\n",
      "path": "std/hash/mod.nr"
    },
    "50": {
      "source": "fn main(\n    old_root: Field,\n    old_leaf: Field,\n    old_hash_path: [Field; 3],\n    new_root: pub Field,\n    leaf: Field,\n    index: Field,\n) {\n    assert(old_root == compute_merkle_root(old_leaf, index, old_hash_path));\n\n    let calculated_root = compute_merkle_root(leaf, index, old_hash_path);\n    assert(new_root == calculated_root);\n}\n\nfn compute_merkle_root<let N: u32>(leaf: Field, index: Field, hash_path: [Field; N]) -> Field {\n    let index_bits: [u1; N] = index.to_le_bits();\n    let mut current = leaf;\n    for i in 0..N {\n        let path_bit = index_bits[i] as bool;\n        let (hash_left, hash_right) = if path_bit {\n            (hash_path[i], current)\n        } else {\n            (current, hash_path[i])\n        };\n        current = std::hash::pedersen_hash([hash_left, hash_right]);\n    }\n    current\n}\n",
      "path": ""
    }
  },
  "names": [
    "main"
  ],
  "brillig_names": [
    "decompose_hint",
    "directive_to_radix"
  ]
}
